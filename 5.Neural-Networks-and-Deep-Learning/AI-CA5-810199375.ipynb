{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<div style=\"background-image: linear-gradient(to left, rgb(255, 255, 255), rgb(138, 136, 136)); width: 600px; vertical-align: middle; height: 40px; margin: 10px;\">\n",
    "<h1 style=\"font-family: Georgia; color: black;\">AI-Fall 01-CA5</h1>\n",
    "</div>\n",
    "<div style=\"background-image: linear-gradient(to left, rgb(255, 255, 255), rgb(138, 136, 136)); width: 500px; margin: 10px;\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/f/fd/University_of_Tehran_logo.svg/225px-University_of_Tehran_logo.svg.png\" width=60px width=auto style=\"padding:10px; vertical-align: middle;\">\n",
    "  <span style=\"font-family: Georgia; font-size:30px; color: black;\">University of Tehran </span>\n",
    "</div>\n",
    "<div style=\" background-image: linear-gradient(to left, rgb(255, 255, 255), rgb(138, 136, 136)); width: 400px; height: 30px; margin: 10px;\">\n",
    "  <span style=\"font-family: Georgia; font-size:15pt; color: black; vertical-align: middle;\">Saman Eslami Nazari - std id: 810199375 </span>\n",
    "</div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Assessing and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = 'dataset'\n",
    "\n",
    "train_df = pd.read_csv(f'{DATASET_FOLDER}/TrainImgs.csv', header=None)\n",
    "train_labels_df = pd.read_csv(f'{DATASET_FOLDER}/TrainLabels.csv', header=None)\n",
    "\n",
    "test_df = pd.read_csv(f'{DATASET_FOLDER}/TestImgs.csv', header=None)\n",
    "test_labels_df = pd.read_csv(f'{DATASET_FOLDER}/TestLabels.csv', header=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will choose one sample from each class in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = train_labels_df[0].unique()\n",
    "\n",
    "classes_sample = []\n",
    "classes_sample_label = []\n",
    "for c in unique_classes:\n",
    "    index = train_labels_df.index[train_labels_df[0] == c][0]\n",
    "    classes_sample.append(train_df.iloc[index])\n",
    "    classes_sample_label.append(train_labels_df[0].iloc[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADxCAYAAABoIWSWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAACb0UlEQVR4nOydd3gc1fWw3zuzXbuSVr334t5tbIMNppneIRAS8gukQxJIIPnSGymENBJCCAkJndCb6cYV996reu9ltX1m7vfHiu4iyZJWTvZ9nn1s7ezOnLMz99x7zzn3XCGlJEaMGDFijA5KtAWIESNGjP8lYkY3RowYMUaRmNGNESNGjFEkZnRjxIgRYxSJGd0YMWLEGEViRjdGjBgxRpGY0Y0RI0aMUWRUjK4Q4hYhxGYhRFAI8dBoXHO4EUJYhRAPCiFqhBAeIcR2IcT50ZZrsAghHhNCNAkheoUQB4UQX4i2TENBCFEqhAgIIR6LtixDQQixol/+vv7XgWjLNBSEENcKIfYJIbxCiAohxIJoyzRQPvTbv/fShRB/Genrmkb6Av00AncCiwH7KF1zuDEBdcDpQC1wAfC0EGKylLI6moINkl8DN0kpg0KIccAKIcQ2KeWWaAs2SP4KbIq2ECfILVLKf0ZbiKEihDgHuAv4FLARyIyuRINDSul87/9CCCfQDDwz0tcdlZGulPJ5KeWLQMdoXG8kkFJ6pZQ/lVJWSykNKeUSoAqYGW3ZBoOUco+UMvjen/2v4iiKNGiEENcC3cA7URblf52fAT+XUq7vbxMNUsqGaAs1RK4EWoHVI32hmE93iAgh0oEyYE+0ZRksQoj7hBA+YD/QBLwWZZEGjBAiHvg58K1oyzIM/FoI0S6EWCOEOCPawgwGIYQKzAJShRCHhRD1Qoh7hRAn60z2c8AjchTqIsSM7hAQQpiBx4GHpZT7oy3PYJFSfg1wAQuA54Hgsb8xpvgF8KCUsj7agpwg3wWKgGzgAeAVIcTJNONIB8zAVUSeo2nAdOCHUZRpSAgh8om4DR8ejevFjO4gEUIowKNACLglyuIMGSmlLqV8F8gBvhpteQaCEGIacDbwxyiLcsJIKTdIKT1SyqCU8mFgDZE4wcmCv//fv0gpm6SU7cAfOLl0eI/PAu9KKatG42KjFUj7r0AIIYAHifTyF0gpw1EWaTgwcfL4dM8ACoDayK3ACahCiAlSyhlRlGs4kICIthADRUrZJYSoJyL3+29HS54T5AbgN6N1sdFKGTMJIWyASqSR2IQQJ6PB/xswHrhYSuk/3ofHGkKItP4UH6cQQhVCLAau4+QJSD1ApIOY1v+6H3iVSFbMSYMQIlEIsfi9diCEuB5YCLwRbdkGyb+Br/c/V27gNmBJlGUaFEKI+URcPCOetfAeo2X4fgj85EN/f4ZI5POno3T9E6bf7/NlIv7P5v6RFsCXpZSPR02wwSGJuBLuJ9Lh1gC3SilfjqpUA0RK6QN87/0thOgDAlLKtuhJNSTMRFIoxwE6kYDmZVLKg1GVavD8AkgBDgIB4Gngl1GVaPB8DnheSukZrQuKWBHzGDFixBg9YoG0GDFixBhFYkY3RowYMUaRmNGNESNGjFEkZnRjxIgRYxSJGd0YMWLEGEWOmTJmEVZpI260ZBkSHrrapZSpRzse02F0iOkwNojpMDY4lg7HNLo24jhFnDUyUg0TS+WzNcc6HtNhdIjpMDaI6TA2OJYOMfdCjBgxYowiMaMbI8bJhBCgqAjTybiKPgbECt7EiHFSoSbEI1wupNWMXlENsRWlJx0xoxsjxsmAELR/cS7yok4uyNuLSw1w/5pFTLizAa2hMWZ8TyJiRjdGjLGMomLKTKfjjDzG/98+bkhbwwRLFxYhcJ/u5a8HLiPrbRfG7pOulv7/LDGjGyPGGEYtzqdzVho9l3m5P+8NrMJMjyFo0RW+lNDIn07txXcoHtvuaEv6342wWlHdiWgF6WgOMwCqX8PU0YdRWYPUtAGfK2Z0/1dRVBSbNRKYeQ8pMQJBMPToyTUYhECoKsJi+UAPKZGh0KAawYigqAizCSEERig8pN9UcThoWpxB2uW1rBu/BLBRr/XxpreEdzrH8++Ct/hU6VZeyTgd2/BrMDwIAeJD8fqT5dn6EMJqRcnPoWt6Ku2X+SnLbEQRkoMtqajb0in4dx9aa/uAdYsZ3f9B1JRkAtMKaPxSiEmZTVgUnYBuoqormeQ/OjBv3I/h8x3/RFFEjY+HnAza5yQTvKybDJcHs6rTFbBjPJKGe8le9N7eqMkXOmc69WeZkdkBiv5qYNpXi97VNahz1N88jVlX7uKfuSsBhVqtjzOfuZ3ct3Ws7X5ang/iUgMYZhAmU/Q7miOgTigjlBaHZlcxezSUd7efPP5nITBlpFP1hSLGnXOIf+Q9xjiz9YPjJdAw18fZU79G6W0Cral5QKeNGd0hIEwm1PQ0MAz0zi5k8OTZ19Fz7VyazjA4f+ZO7k5ZxfZAHu2ai3RzD5Nz67nrzvPp/m4Z6s4KDM+o1XUeFKacbOqvziflwnpuyXmGabZ6bEJHRRKQKm//YDxPcR5JaxrQaupGXT7PtXNpv8zH/bP/jUsJcG33LZQ8nodYO0CjKwSmrExyL6jmq+nLAJUu3cfZj91B8cte1KpmjLx0dAkz7NX8M1mgJCeht7SOqF4DRZhMqCnJ1F9bTP7llcx378Bt8tIajuf1Py4k9e2aSPBvDKPExUFxLlU/NvH/Jj3NqfZqHAIe96Tx8yVXYfIqWKZ28dL0f/DA7Mf48Zwv4FxvDOgexIzuQBACU3oa4eJM+nJteDMVfBmR3jquvgj3wRC2tQfGrJGCyFTVc/5kuq70clP5JmY5qrin+WzWbJiAySvQCwLcOetFfpKzhOtO+TbZPdkwBoMzSlwc9Vfl41zczC+LXmCSJcxfuybzetNEDCmYnVLDL9LXc8/p52DrzMBS1zh6U1ohMBXm07Q4zLcmr2SCuYcfNy3GdVjF1OVjoFIodjut5+bz9cxnmGDWadKD/LFtIflvBlD31yADQSLb9PUzhgaOwmqFSSXUnpVA4YWV/Dr/BZKUiOYJioVXrpiErykLW69nzLYXxeUiPLOUmvOt3D31UebbWnjbl88j9fOo2pBL4ZsBVJ9GtUikcYqDebYgnhwTzgQXjKrRVVSEqiK18MkzfTgOwmpFcTgQifF0z8qgdZaCe1I7n8rdyVRHDWFp4q3uSby+eQqlfcWIdbvGpM9KcTigKI+uT/fx5Ix/EULhH61nsO25SYx7vBKjpxf/GRO5y7mYzbOeIDDbi7ciHvseMbbupRAoqcmkXFTP1/OXAfBA9wT+vvxMMtYKhAGvzMjgh9e/yw1z1/LivtPJWm3D8HpHRzxVpXdqOl+f/TZXufbwtq+AtS9OpeDZWvTWge0oJKxWRE4mgUt6WGCvBky868/lpRVzKFm/DT0YRHE4kKpAFdCguTH5AX9g+PWxWlHsEW+x3tN73GdBmEyI0kLqFyVw3rXruDtjG7WazmveElrCCdyQuIUXpz3IxeO+Q84B95g0usJkQo4roH6RjR9c+iwXOnp4ri+Hn2+/EOeyOEqePYDe0YkE4mbMoy6czKm2LoKJIB3W450eGEajqyYnQUoiNLcP2nc1VlFKCuiYkUTraRrPnvsXJlkEVmGmVuvjF02LqfQk85Oil7lh8Rp+VHYZ5utTBuVQHy3khCIOftbJobn3sT9scMWqr1L4sCDrnbW85wV0bKwEimid7uOa8VtZkr+AOKsVIzD8jXmoCFUlWJjC+IQ9PNR4KnvWF1H8dC+l2zZHfnNFJXFjNg9cOJVvJW/m0dLTEJlpcHhUdtZGmEw0z1OYaq/hTV8RP994EaW//uA3HghKSQE1lyazfc5fMAsnz/XF89MdF1F+dxVavxtL2G2EEq24hMI+fxaWHjns/mthtsCEErrGuwBwv7YPvbfvmM+2mpfD3ludfHf+S3wlsQGAzx/8NB0v5eBs1Nn4jQKeKXmNkBuMhLFZsEZNT2PfzRZ+Me8prnW2UaEFuOvP11G8tBX9wM4PZiuKihSg9y/qFQZgGAO6xrAYXTF9Igc/Hc+lZ27ghXWzKf/e3jHZiw0G3+WnIL7Syl/K/kyBKUSyYud3neXcv+F0Mt4xkbS8Cmu4j9sv/ip9F3l4ZtY/+PR13yb7UQ29vSPa4r+PqSCP+tPi+cMFj9Cq+7jykTsoedOPsnHvR2alRo8Hx+FOnuydwleS1vFE8alkZ2VgVFZHS3QATLk5yPg4hD+IVlmNefMhKm4qROkLUNK2G+n3f2AIDB3p6ePBPfO4at420ovaaT8tA/coGV3MZqbOO0SRqYefHb6EzCWWQX1ddbtpnZfEddcuwyxUWnUvty//ImUPBtA+PG1NS6ZzvBm36kAVA2vog6Xz0zMJX9HFs9N+B8CVKd8h640W9IMVn5Q7MQHvaeVM/MlOfp36H/JNkp0hwWWvfpNx93WTWb0DSvLY15xOuFgnkBnGn+3EumNERP8EisuFf8E4+jJNJO/qQz1U/8mBoaKiuhOo/2sC9096hPk2D5uCZm7+ze1kvnQYve2TbVoqApsID16eoWmhRl4AQlDxqXjOPWMbl7q3orhDCPXkL+mg2QQ5zm4mmHWcwszVFYv5z9/PoeRhnaTVdWjNLegdnaSuaMC0Np7X+ibhOLcFkt0f/DZjgL7JGfROCjHZ0sxZG79C7jsBTHtrkOHQRz4ntTDC62d9dyEqgEkix8B97FiYw75bEjj4lUzU8hIMrw8O16LXNWJ4PJ+I2MtQGHEojm7DQq6rG1+6OMqZhxc1Ph59chFfylzJobCb+sNpJG4eWDT7PTxnlNFxaojrEzYDcOnuG0hda0LdX/ORqb2WFIenIGJslRFw6JoyM+g4J8AtZStIV0006w50K3CE50EtL6Ht8gnYv9XArWnvkKsaPNg9kcte+Salj/qRFTUYPh/SrJKT3I0qBIpDQ7OPzrNlKsij58KJJH63lvlf3czBL9jovKD8k5/LyqDmy+P4xcSXmG3tYak/hRs2fp6MpU0YHZ3DOnsd9EjXlJONf0ImoXgVW0cYJaAzcV4l1yavp02LR62yIcNjL3VlsMQ1hVi3q5SvKTp59i72v1VK4St1aHWNaB+6AVp1LUn703mmZga3l77FA1lXYm50jI2RvqLSWW6iqKCeXaEMnEtcmHcfOLL7R0pkKEyrz4UOSCE/msM7Sphyc5BOO+gGsrYBBKTnd+IPmQllxaMe0I+dzqbruGrAY9goiWtja1ppRI8R9k2LpETaZsRxiq2XX7XNw1GrotfWD/j7alkxjQsEV0zZRo7Jzgq/Qt876eRs6/yI60CYLfRlWcksj4x8+3QrwzrYVVSC47I4v3wPGeZu/to1mVcaJmPplaB91PCopUU0L0olcLaHl0ueIgz8rWsG/9hyGoUvabB+J0b/OQ2rifKEVhQUpCGGV+ajIEwmvBPSaTpT563il3AqNjSpsrxxBgkf1iM5Cd+kLMaff5DFjh42B238ofIcEt+IQ6vcOexyDc7oKiqdC3PRr+/gwpw9PFs5jb4WJw/nvokFnQfqFlL8aBv6CDj1Rxt1xVYm1BZQM2Ec2yaYKHyiBr255Yg9nr3RS9O2FK6Z3sNvi62kVyeNCaOr2Kz0lYc5L6mOXx08n6THNqGPwVzO91FU2s/IxZstUMKQ+1yY5OW1HJqUTzhRJzEOjjeHkGENV10Yr7Qwx1nJ87lTUUbBNx3OdOM91YtTWFlSOZGEGmNgebNCoFit1F2SzufPXsYdybvoMkJ8e+915D3XgFb10bKsSlIiPcUq95S+BMAhTxqmwPB1KMJsonmOjVsS9/Bm92ReXzaLtM2SxI4QwvNBQFKx2Wi4IIP8Kyp5puQVdGnhT52TeeSFsyhZ6kdZve2Dc6oqmk2l0N6GgoBeM5bekX8OFZeL1plm7jrjcezCQljq5Ns6CLs+sPjCZCI8KZ/6RSaWFy+lz9D53qFr6F2SSfojG0ZErgEbXWG1YswYx+d/9DJXOw/jVh38JHUvujQISo1Tt9xAwt9dWA9sGhFBo4FWWY2tspqsJRwzGCKqG8hdaqP1c146ZmvE16ZirjpmHeZRQTjsqA6Nda2FWB9MQmqHjv5ZkwnhimN+aiVxIjpuBTUpkUk37+Ku7DfZHEzih903kvr4Nop+1I5QFaSUA5pMS1WgIplgaWZceishlwtG0OgqNhu9OTa+PuUNglLDvCKBxC3NA0oRU9NSabqyhH987S9Msei06CEe6JxH+v8T6PVNn/i8f3o+vvEBzrJHzn5gWTH5+3uGzckgTCYcC9soMrfz4/oS8t4MYXpnC/BBG1BsNupuncFdX/gX59q9NOlBvlN3CV3fzqFo7+5PBPUUu41goonFzj2owoa1TcXS1sNID3bDkwoIlvk5x97EpqCV6nAKh31pCP2DGZw+dxKVX4ClC+8GnFyw5zqUe1LIXLYV41hBw9RkQgmQYeoGFJQwCH1gd2HARlfNTKfhO2HOchzkmoPX0dgdz88nv8KVzl7a9RC9HjtpnUEUl2tMjPJGE6PPi6W+i392zaCgqBVvRhaJHzquji/FW+LGl6qS/PjWUVtMIX1+sv9jxjCn4lp56NhGQChIk0qCyY8SBbcCRIJ5m56exVkLcylOaidle+/7S2jlYOIVEnQENgEOU4iwOriA1mBRUlPwZqpc4NzDUn8aiZVhZGPLcb8npk+k7pwE/t9NTzHFouOTYb5TdwkV/ywn+fDWT/jdAZpPMbOofB+6NNgTDpG6XUOpbx1wDvBxZbJYODd7P41aAn01CeRsP/iRiL0yuYyaS9z86oZHON3Wzd0dU/nH2tMp/6cPZe9hdL//E+eURTl0lasUmcBnhCIGKjy8GT5qfHzkWpr2vvupc4KNgswG2gzJl3d+Bv/eRLQ4SXy9iORU5+VQf3uQ3098BbOA77dMwXxXEtYdFejHaaMyM4VAmsEEc4CwtGLxSAh+8n4diQEZXVN+Lh2nZfGjiU9yX/tCGlbkogagY4IT6KVRs3NKYTXrbirB3D6JtC0G8Xu7oL4Zvc875lKohhupaYg+HyvbSjkj7RDPZmST9KHOp/GcVDyz/WSmttNqmUHGf/aid/eMuFxGIIhzWyR1R+s8ThqfIsBsIt3cg0p0jK4Mh8ha3kN3SwJViW4yaw6gy8GPh9SgQcCIGFqTMvLPnp6eiD9dkqKqPNBwOta2AMZxXGzGadOoO9fOlDMPcJWzGauw8JWas9m2rJzi1c1HbPTCaiWQG2J+wmE0dOq0RBwNPoxhShdTHA6MgizOjV/OfzrmElevoHf1P6dCoC+cSu3pNk67YAcXOnr4Wdtsnlg1n/zXDdi+H+Mo7pSw20YgxcAuLGwKSmwdEtE9PAMzYbYgJhRTcVUi0gzOGsh4vgK9pRVfpmBWfBuduo3gzkQytupoNgV7WxBhsdB6Zg6fL32dyZZmlvkKeOGl0yjcsT+i83FiAHqcBcNu4FSs9BlBzF6JCA5sZDAgoxssTKX1FMnlcZ18d9mnKFwXJJBiJlntIyx1numaTa6ji0sWPotL9XNb4TX0bkzBfTARe7MPta0Ho70z8iD+lxpgGQxR0ZLJdwpe57GU01ES4t83uj0TNG6fuZQrnPu43Pg/xOvxMMxGV3E4UJKTwKRCKIzW2ASGjlbfMKDvC4sFLcFGgbk98reMkuHdtofEXSZQVfRgENXtRmoaMhA84sjvkycwUAMaAWkeeWH78Wc6CGWEURHsOZDD+O5O9KM95/2rGw+fZ+eMc7dzb/a7mIWZNQGD9SsmUvCGH/0oKW5KYgJJ6b1Ms9USlgYbvcWonX3v5++eKMLlpK/QyQxLgFsaColrNN5vr6aMdGoW2Zi3eBf356xmTVDliZWnUvCqhvmtzcd0b4QSTBjuMKpQWO8vwNFmYHR1D4vMit1G+/REvnPVC5iFxm92nwfvuKC1jUCGRrmjhVbdhXu/xLWzFXQdQmFIctN9jp8z4/azP5zCXw6fSeETLeidXQMKuupWFcwGCoJuw8DskxAeRqPry7CQU9ZClRag8FkdS0+IltlWrnT2UhX2s+zfczF5Jc9MP4V/XfgPdi14EP00yeaQhfuazmTLu+UULEnBfLDhg5U5Y2ml03Cg68gWG6mqFy1eR8Z/kPydsMfEU4WzOLP8AHnxXXgV5/BeW1ExppRQcUkcukNib1LI/Uv3oIrWKMlu2sY7mGX14TE0RFAgopSFIjUNNA1htdJ7ZhnWLg1rffcRc0SPhNA+GB2rYuSfM0+2Sm5OG2FpYK81I/xHN4KK3U7D1cX8+OqnuDyuCbOw4DNCfO6Fb1D6VA/G9r1H/a6en86MtEomWQRtusaj209hvG9gnepAEDYr3nQFqzDjaXGS1NnfcQhB06WFXHjRen6fuZVW3c+Nz3+b8fc2Dqi2hS9VpSCnBV0a7PDkYunRhi+wabfRNQ7MQmN593hC1U7obEKx28nI72CGvZr9wUziK33otfVITUNNT6NvbgGrTvsDAFduvJb8fyjoB7cO+LK6XUGxRtqHR5pQAwMMnDJAo+teWU2oPoP/y/42Cet24Tl/EoEJfnxGiCt33ETGu93IPYdJfcHObx6+jsOfdjHjlEPcmPEu/8p/g2DeEg5dY+bBtoW8vW86CZtsZKzoROnqxRjDa7AHgwyFSNol6LzEQXpeJ+2zU3H3t5+MB7agvJPPl8pvI666D+qPHtAaCkJVaZnl5PbLX2SctZFfVV+I8rALw+8fcOcWykmiY66GU7Hxpi8eW7uC7I5elS7FZkNOLuULv3wBlxLg53svJP3uaYg124/5PWGx0DbdSbYp4k7x62bkKHXwOhJ7+1FGPEKgTiij5tJk/nrT/cyxBjALlVd9Nr79xFcpu+fAB1P5IyBMJuoXubjcVd1fU1fDvdaK9H3ShzpUjIQ4eksiv5XiVTH5Q+8vLPjKN1/iMuchHunN56fvfJlxvzyANoClwYrNRk8x/LDgHQwkq9ZPpKy1e9iCaHprGyW/8PLUvacgAwFKfTvR/X5MOdlMSW4kSfVxyJ+O2u5BNySKy0XPwkLybz1ImupgyvrPkvqyDdPqY4/WP44UAiFAQ2dvMBNHTS96Z/eAvjsgo6u3d2L2+3FX2NF8Pkw+A9lt4WVvOsrLSYimCoxwCL0njLK/mtJH82lZXsz/KyynZ6LGgqn7+XTqBm5IWcOF83ewc3oeu6/LYl9bOr3NOTgrTGSt9KB29oHHi/T0RUZpinrSuCOklNg7dALSTF58F3sz0nC/dywYRFbW4uroRvZ5MbTBr2I55rW1MBmru7g791KEAe594O7aOqjZRMhtYXxJJK/0wYbTiGuQUe0MjVAYtbqZX20/j59Mf5UfTHiNn9x6CYUHU9GPkawuTCa6x0uSVB8HwvEcaE8jYxhHg0civk6jpjYF20SVzuk66aviI4VP+n9/U1EBjedl0Tvfz83T3mCW1Ue7ofGzxvNYuXoyZU91Hntaq6gobjdFF1SywHGYdt1gmXcCaeu7j+s7HgyGwwKZARQE5j6BVAXhWaXYbm/k4riD/L79NJ5Zewpl//aid3cP6PkyppUhCrzMsjbjkyruXQKl2zN8mQtSYni9kd9BGhGZFJVgSRoljn0kKpHRp9B0hCLovGwSXRf4+GPWW9zZPhXXCy7c6xvRBplKaZgFihp5BgPSHMlhHmD8YUBGV4ZD6N2h9/2Q9noPydvcfM96FePXtCN7ej/yA7B9L/bdJpwZ6bgPZrKlZhLvji8hL6OT8sQWEs1+vpX1Jt3pDvaWZrNifDm7sgsxeZxYuwXWTomjXSccp2D2Gtha/KiVjWNqee0nMCRqUKIjSDAH0O0fOxwIjFzakpTI/ZXkvz4RJahjrm0blJ9PTUzAm6FyeVpkaL5/by6FdVEuBG7o6B2dJL5Rws/kRYzL6s8GON6DbbXiLOjBJTSWBfLoboon3X94REV1VPXgqEzhQFjh3Bm7WH/udBLK3ShhiWEWtE8y4T6tme8WLudaVxcVYY2vV15Dxbv55C8Poe85cMzzK3YbWmkW3855jHyTYHPQxX/qZhJfWR8pMDVMSFXB4Yg8N8FUnZbZVoJJkjeKn2JtIIunN8wh922J3DzwbSp8mXbSEttwKSrrAokk7fNh9IzADOpjnXA4zoRNaLiEQq6tk63lM1CKUmk9M8TXJr+LTeg8vGIh4za0otUOvlMOJCq44gKEpU5NMCXiKx7gIGdItReMnftJ3mch9WXXUQ2h1DS0+gYs9Q3kvBkpJBEuy2ZbUSbBJMHWi3I5O20/0+3VXFqwm8QiBaswsS1k4l1vOcvbypie0MK+7gwqt+RS+FIuYiwbXUAKUJEYUox6uT0ZDKKuiPikBmsqjdI8ekrhYuduegyVlI0KtorWQZ9n2DF03A+tw71/Cl1Z+aTqMjKFO8Yol0QX5+btJ1FR2NhdiKNm5It7G4eqSdmVyANtp/PHrJXcdWMv27pz6Q7YSbH38c/8F0nvX0JbEdb5S/sZdN+fR8naOrS6D61a+/AuCx/SUXEn0jgnjlnWPuzCyuu9U+hcm4HTUzm8ikiJYUSuf8b0fdhnhTkvcSeZqoXzt15G0TM6pmUD93sCaHZBvDlEu67zz6YFqLsqR2UGZfZq1Icic80FjoP85bzzICXIz2a/wlx7DX9vX8C4v7ZhVNcPfjatqHhzBLNSmglLgw2dBQPOXIATKHgjw6FBjTz1llaUllbcq/vf+COsyh/Hm6ULaZ9ixXZWG4uyDrHQtZ/rE7bx3eR+v2cm3BJ/CqubZpKxZqjSjg6iPz9UEZIoZV190HAH+CAJs4VD18Xx+bOXk66a+FLN+SRv6UJv+GRiftRYvxPHAD6mZmfSdmo630p5hHjFwZ62DBIrRn69qQyHcG6uYc9vp/DYL2q4NWkT7tQ9H/pEHC97HdxXt4ialfkUPtNOfMW2T8xG1JQUhCsOaTahH4iMzoXZQqg4jbmf3oZDWNgTDvHC/qkUP9857IsLlLCBrzdSyvHfeZGG2q57uatjDiU/9GDUNAzaP64GJUHdxJ5QGrtWlFIY2DLMUh8BQ8e0eifPvTMX9SyDX6XvpOJT9wNQr/Xxlcqr6bs7B+vBoS3kUovzMc/s4gvpq+g2DPbvzGNcYGBBXohyEXO9oQlrWwc52+2IF13sspayOXMm/jQzIafAMEUMmbNBJ2dbdfRHXsdCEYRcCmZ0PJoVZTQ3k1BUwmdOo/oyE9JsEFdpJvuutQP6Xs0PZnHDWSu4Mn4rj/WW0vqDQsxVB8bk1i/Hwzc+A+2KTtJUB+uD4N+bSM6G+lF5brTWduKXBniq83zum2hF+1DlQiUEKbtD2Ko6Kew9jNHZfcT0t9qbSrGf1k55Uist35mGafN+UFWCiWZuSFmDWah889AVxL0bhzw0/AXmldoWsl4pZMvpOlMtOvVakPvaF7Lxl7Nx1u8YWMrex0hYX0ddQQHfLP0MhavDSH10YjRS0yh50sOzoVMxX6hza9Im/tkzmb+/eQ45y3TsK/YOutMSZgtqVjq1v7Vx96TnOMUa5nBYJeGAAoNw50XV6EpNizRunw/6R82Wehc2ZxxYLUiTijAk0utDO0JptbGEYrXSOkshTe2jptdNXNPo+ReEqtIxycr8GXvZ15GGti/lmJ9Xk5MwCrNoOCOeRRdu5dL4bSzzlfO7FeczfvsB9DG2P5paXkI4w4VuVbEs33nExq+WFNI+2czXS1ejCoW76s4j4TAYLQMrHn7CGDp6dw/WzYfIakhDWj9oWkIzoLHluAtibO2SkKbynaw3uOyLX6PcU4iobcbWHuKXNRfxYPHT1O3MpHC3f0RWNRrdPSRsa+Hal79OcnEnXT1xWHfbKVhXOeRcYL29g6wVboK77dj3Nn2kWNRIoxyqI//NYl5sPZ1Hxp1K/H4Thdv8WA40og2hsL2ak0nV9dn8dOLjTLJ08KYvjbsqziN9Q8+gAppjbrsew3MSppAJgXA5KZpVR5Iapq0znvy6wY8KTgSpQovfRWdDIvkHI/4lYTIh7PaIr9NkQphUjPQkeotddExSOeuiLXw1dQVr/MXcs3MR+a/IUVkpNyiEoHdSMh2TVYIpOoXaZGyVbRgdXRh9fSAlakoyHfMzCM7s4zLnIfoMlb2bCyg8FBj1Iux6by8McYVY8m4vlSWJdE52cP+pj3Ln85/H2dyBuaGT6rcK+PFli0nZBpaDTSMyepfBIFpVDeX/stM5NZnsTh3n7voBb7h4tHOyZQ8WBh9rOFH03l6UVdvJ2uwgs6wAdh9ChkNDk0MI9EQn6sxu8kydvOCZyD8PzUdZ6sa5dd2gMoXGnNEdE3xsW/LjoVit6GluflD4OA4hkK1WbBWNo/aQyXCInAf3wJJUJvTWvt9I1JRkwsWZBFIthB0KAbeC+YI2vlD0Clc7D2MVJm6suZB9z4yjeEU3xvbhL2M3HHSOV5l73i7+kvM2f1o4jSefPJOstcmYd1Zj9HnpPquU9JuqeLTgOdyKjeV+G3mvhzHvqBi2mgSjwoZd5Num8/m0G3npzHvR7ArCZEKrqSP3Dy3UvVVC0qG9aCO5y7GUGDv2kdhfYPzkczJ9jPcyqrbtOf5nj3MetbsPfUs2X+SzWN5IIGtdF8bOAbjxPkbM6H4YRUVNiCcws4hAshlbRxhbU1+kEPMxRkzaKeOpuFFwqtXgS3WLSdwn0BuGPjoYCnp3D3wsWf3grUV87oLl3OyORJwVIbAJE2/6Erjm4Kdofz6XzKcOkNmzedhzh4cNKSn4236qN5Uz+fLxHLz4b3z95m2svDGZpT0TOdibxj+K/ki+SaCj8LrPxU9//zkyth2I6hbsQ0JK1FU7GL81jtsnfZmEHbvenwbLYBC27kX/b1vJeRKhVdWQd1dTpOKdpmEM0T8dM7ofQk1KxDeniAk/20WqxUNzMJ5qTzJVbWVorXZStig4m8JYG/swdu9HdbvpOr+c5rM1/nbqoxhIVi+fTMFu37DmTw6YjzXIvLdDPBZaxINpCzF3qpj7BIoGjmaJqzZIVlUdWkfnmF+SrXf1YN9cSXlnNhN6bmHi3EquSN/CLakrCKSolJktrAuq/K7uPCreLKLg9brIRoonI4aO7vFEUqs+7lsf4/fpfwEZDg2u4t0RiBndjyOgzNHMp+P3YBUKnbpOZUECW/0FPFkwi6oOJ2pHIgkH5xFKFGizPXxl3HpOs/Xw/ZZ5ZGzQMVc2o42BBmLdUU1uMBctzoS104/SF0AEw8ieXvSOzpNn6ti/UIKuHgrNk6hqKuYn4/JJyenGYopo0diQhHOfhdx3egZUD2BMI6O7GjDGyBIzuh/C6PHgqOzmnlXnYixQOMVxmFTVT66plyznLj41bQdmwCMFq33FZJu7KDJ3oiJ505fFq8/Po2Dd4Y9uIhhF9PYOlHc7sBBZq3FS+TePhKEj1u4gYy1kp6chU5OQ1sjSvwnNjRgdnWNq9+IYMY5EzOh+CBkOoe87RNlXYWnZdP4zfzF92QJpArMHPGUa5sQAyQleLszew/KucextT6f3oJvMNZLcF9ae/IbtJEFvaY3UN+jnpBm1x/ifJ2Z0j4JRWUNyUysplv66rLoOVitCUcBiZo1rGorXT2a4j4xgJ9LrHfHtR2LEiHHyEzO6R0FqGvIYfjVhMg26MlGMGDFiRGcHwv8CTsZlsjFixIg+MaMbI0aMGKOIOFbVICFEGxD9vcSPTb6UMvVoB2M6jBoxHcYGMR3GBkfXQUo5Ki+gAHgN6AKagXsB02hdf5h0GA8sA3qAw8Dl0ZbpOPLeAmwGgsBDHzt2FrAf8AHL+x+SqMs8UB0AC/AsUE0kI+6MaMs6BB3mAm8DnUAb8AyQGW15B6nDhP73u/pfS4EJ0ZZ3MDp87DM/7n+ezh4pOUbTvXAf0ApkAtOA04GvjeL1TwghhAl4CVgCJAFfAh4TQpRFVbBj0wjcCfzrw28KIVKA54EfEdFlM/DUqEs3MI6oQz/vAp8h0omPZY6mgxt4gMiAJB/wAP8eVckGztF0aASuIvIcpQAvA/8ZXdEGzLGeJYQQxcDVwIgWkx7N7IVC4F4pZQBoFkK8AUwcxeufKOOALOCPMtIlLhNCrAE+S8R4jTmklM8DCCFmATkfOnQFsEdK+Uz/8Z8C7UKIcVLK4S/UegIcTQcpZQj4U/+xMZ0efQwdXv/w54QQ9wIrR1e6gXEMHbqB7v5jgsganJLRl/D4HKM9vMdfge8SGSCOGKM50v0TcK0QwiGEyAbOB94YxeuPBAKYFG0hhsBEYMd7f0gpvUAFJ1cn+N/IQuAEy2FFByFENxAA/gL8KrrSDB4hxNVAUEr52khfazSN7ioijboXqCcypX1xFK9/ohwg4h65QwhhFkKcS8RFMpCdZMYaTiJ+6Q/TA7iiIEsMQAgxhYg/8Y5oyzIUpJSJQAIRv+m26EozOIQQLiIdxTdH43qjYnSFEAqRUe3zQBwR348buGs0rj8cSCnDwGXAhUR8iN8GnibSgZxs9AHxH3svnohPMcYoI4QoAV4HvimlXH28z49V+mdM9wOPCCHSoi3PIPgp8KiUsno0LjZaI90kII+ITzcopewgEjC4YJSuPyxIKXdKKU+XUiZLKRcDRcDGaMs1BPYAU9/7QwgRBxRzkk5tT2aEEPlEIv6/kFI+Gm15hgGFyOwvO9qCDIKzgG8IIZqFEM1ALvC0EOK7I3GxUTG6Usp2oAr4qhDCJIRIBD4HjM2tCo6CEGKKEMLW75e+nUgmxkNRFuuo9P/WNkAF1H7ZTcALwCQhxJX9x38M7BxrQTQ4pg4IIaz9xwAs/ceitQ/zUTmaDv2xjWVEBiP3R1fKY3MMHc4RQkwXQqhCiHjgD0RSx/ZFVeAjcIxn6SwisZlp/a9G4MtEAmvDzyjmyE0DVhC5Ie1Epubp0c7dG6QOd/fL30dkOlgSbZmOI+9PieQcfvj10/5jZxPJ0/X335eCaMs7BB2qj3BszOlxNB2An/T/v+/Dr2jLO0gdru5/jvqI5Bq/CkyJtryDfZY+9rlqRjBP95gr0mLEiBEjxvASq70QI0aMGKNIzOjGiBEjxigSM7oxYsSIMYrEjG6MGDFijCIxoxsjRowYo8gxC95YhFXaiBstWYaEh652eYzamzEdTgAhEBYLlqIQcUoIr2Gh12vHWuv7xEfHrA6DIKbD2OC/XYdjGl0bcZwizhoZqYaJpfLZYxYzjukwdNSUZLrPLuXRu35HgSmR+3vy+d2K8ym7eRN8LNVwrOowGGI6jA2iooMQKFYrwmLB8PlOeDuuY+kQ25gyxtFJjKdtuiBdNaGhs7qrlOSt6icMbowh8F4jt1nBbIm8Fw4hQ2GMQBCMMV2t8r8DRUWNdyJsNrDb0FPiCbksWNq9qB4/hDVkOIz09A3rPYkZ3RhHRTqsmIs9mIXK5qDKhr3FjH/pMDFzcOKoiYmEJxXQMdGGpxAUDRyNgoTqMHG7m9Fq6qIt4n83QqCmJtN4TQk94zWyitr5YsGbzLbV8GzPTNZ1FFLVlozW6CDvDQ3H7ka0hsZhuXTM6MY4Iur4UhrOSuLF2XdjFXH8uPISEreZ0dvboy3afwUV3xrHzDP38+fsV7EJA4CAVGjUXbzbV85Da0+j8AUD+656tKaxvTGGsFpR8rIx4u0ffT+oIw9UIsOhKEn2SVS3G/+cYqovU7hw1g5+nPwXckx+whJ2hdLYFMhnqqOWxa5dFJUGCEjJ3ouT+U3l+bSsmU/Ro41oVTUnNNuLGd0YR6R3YhLeWX4KTTa6dB+1W7Ip3OE7OV0LioqpIBejpQ3D6422NACkbTPYoozjqnFZlKa0E2/xMyO+lgJLO6c5D5B5RjdPlszm4LZC0jYXkPDGXvTe3miL/VGEQJ1QRtspSQQv6SbR7kMRkefDkAJ/2Ixnyywy14Wxb6pA7+iMssDQdV45zWdrfHfeqxRY2rl1/6dobY+HLguuSgVzn0RzCEKJ4M/WmDf5EN/JeoPvF73K2ymTeK5wBuV/sEFF3ZCfpZjRjfEJFIeDrlKVC8p3YxYqu8IOEg6C6XDjSedaUBwOZHkhtWclkLHJjeVAI1pzS7TFIn5jPfaWVDx7XFTkJKBb4d308ShJQdKTerkwaw93Fr/Ai8kzeT5zGkp4PHGvbUcGg9EW/SMEMp10j4MvFG/GZ1hwqgGyzN2MszSRbwrz68wFvBQ3hzyjCPNb0TW6akoyLXPhi7NXszjuAF+vuprgkjTyasJY27wo+6oxPB4UhwMlOYlQQSo7ThvP98+185WcFXw39V3OOW03397zRXJf1hAV1UMKuMWMboxPIHIy8ZcHuT1tObp08HTHPFwNGnpbR7RFGzQiO4NDn3Gx9pq7OWXJbeS/nIf19egbXa2+AVHfQPyaj1aTVxwORFY6z515Jls/m8s3spdy44I1/KTwYvp2ZWHUNY4dwysiaf6WLsGDr5yNex+EEgSeAoPC6Q3cXfQsv8nYRMH5Hfwh/lzKl1ui6moITcpn0rRqrkrYyiPdc/D/IouM9TveH7Ea/Z8zfD4Mnw+lrp6c1eDbPpvv3nglz85+gHMdYb5+44v8q+kSkjq60NsH3yZiiyNifIKOuWmMy28iz+REQ2fZyzOxV3ScdBF1YTIRyknka4vfIlmxg9XAsIy5crsfwfD50A9XkfKP9fivs/KFp7/K632TeLzwLTr/rKLNn4h4L9sh2hg65qVbyPnNOgp/uJHEx9aT9td1FH9nE6bLuvnCnbeyKmDha4lV/GzhCzR/ZRbCFL1xXl+OBb9m5gv7P8OK78zHtGzrgFwE1tc3kfFPKxcvuZWw1PlSQiMtZ4XpO614SHLEjG6MT9A2x2BR6gH6jAAr/Q5y3/Qgm9uiLdagURLi8aVbWOzcQ4Xmx7XHgnPvSRIIlBK9uYWiZ3p58PHzqNX8PDjhUSo/J/BcNh3GUq12KSMdspTv/9/o6yP9tSq+vP4GHvekcaq9moKrKhBWa9TEdG/vxvtANvwtFfu6g4OKT9i3VJG5SvCO34EuDf5vxjpaZqsocYNfpBF1oyvMFtTEBEzZWaCo0RbnfxshUJOTyCppY7a9Cp/U2egrRq1pwfB+chXaWMcoyKS7VCHHBMu8ZbjqjJOq85CahjhYS9rWEL9qOo8ys4Urp2ylY5KK4hjj+6FKidbcgn2bnZXd40hRVa7N2IjITIvaSF3UN+Fe34BrQ+2gg5J6ZzdxdX4eaZmPgeTyhK3oBQFEVvqg5Yi60VWT3YSmFdO5MA9Tfs7Yf5j+mxEKMjONczL3M8HioUMXvNNSjvT0nXSuBYSgp9yFnOLBKaw80zgTR1MQw3Ny7b1peDzYKzpYuWYSfUaQG5PWoJf6htTYRx0pSdqvsbcrHZswMdnaSCjXjRJnP/53RwC9uwetpm5oKXiGjqnTy7pdpQRlmCkWG/npHQTz3IM+VVSNrjBb6J1XgPb9Tv756z9y4GtZaDPLoynS/zRCVfHnuTglroI0NY4D4TRal2cjwye2JDIaqAnxtE8T3Dn1JTR0mpflYG7++K7zJweysYWS/3ip0VSKzGZOK6qgZdFJYHQBa2eQXp+NsNTJUiW+NEtkBdjJSEsb+S9JOg0NXRrkObvoLhn8qD2qRldqYUx+gy6fnXFmK/dc/m/qz7Sjpp9Muzf/96DYbdSdrZJl6mFfyMc/GxZQ8GQDUgtHW7RB45tXhntiO4sdrVSGw2SsD8JJmH0BkeCa2FPBTbs/y44QfCZ1LcolHVH1jw4UdVclgRoXG4JxOBQz/hQFrGMkEDhIZCCIvc5Dt2HCQJJg9hNKGLxvPbruBSlRgzperw1VKKSqHgyzRChR93oMGsXlou0r86j+xTyCF84+6dwkwmyB9BTOmL+bDFXn9b5J7Nmfi9HUclIuiGiab+L0zMO06Ro/a7gI28FmjL6xsTBiKBiBIKGVKWzyFzHV0ssXi9/Fd97UMf+cGV4f1k6FDd4SFBS8ORLpODlHusJiIZQeh0toKAgMKT7IMxsEUbduhlnBaovk7jVqbtSAQIZPrpGVMJlQkhKR53dx0QUbaJtiRol3RVusQaHYbYQzEvha+jLcio21XUU4K00YgUC0RRscQqC63cRN7eSM+H3sDaeweX0Zelv7CVeOiirSIHlfmNpgMilqHGc5DtJ0qooYQvR8VDF0bB2Sdzsi6VVht460mqMsVD+K+sFrANkgIimR5jlWXIpAQ6fRn0Bc8+CtbnSNrqISTFCZmx2pgrasZzzWTjA8fVEVa7AIqxUtPZF/T3mY32RswpenIRNOLqMr3An0FNmYabWgINjXmk7ioZMseEbEL62Nz+NLJe8y29rBur5SCl8OIkNjZ/2/MJkGn/IlJdaOIO1BJz4jRIqqsnDhLoRzbI90AeKaDfbXZgCgOMNIU5THekIgrFZMWRmY8rIxZWWgpqQcPatCCBSXC39ZGouu2EKCYqNFD7K7KZOkTYNPQYxyIM1E2KEw0Rmp3vPagUnE12pjZ8XNABE2KyG3lYkWE2ahwsk3GyeUl0LbwsgMo0LzEz4UT/z6Y5Y1HZMoDgeVV9iZa69kb8jFqzUTMW3YN2ZcJMJsIXj2dNTSItTEhEF9Vz1Qx/qGfDaHLNiEiTPd+5A2y9jK2T0C1u4wojPSmTudAQxzdFNDTdlZdF81nU+/s56vL32TS9/ehvGUhe5rZhzR8Jqys6j/8mRs32vknqx1mIXKLVVXYV3rQj9YMfjrD4cSQ0VYLGh2yLdEegtThQ17S9/o2CxFRbGYEXEO9M6ujzRKYbaANJC6PrDGmpFK60wLZqGyPqBj6VQRvSfPaF2YLXjyrFw3Yy0AP6y7hPhDoLedJAsJ3kNREUmJzJh7iCyTxu/qFhLcmIQRPBBtyQAwZWbQMz+fz9/5ElXBVFY0l9JQXY6z0kTSPg3n5tpjpjPpPb34PUU0awlgbUcdikMxCkghoL9fSHF6kaqVqHYTQiBVQbLaxyxrJ/Ns3ZzjOMimn2TzvfOuwFxlw9IjEBqE4yF+Xis35b/Gpc7dgINftZdT93QR2W+3oA+hM4+q0VVSkwkkC8ZZWmjXDZx1oHZ4GA3PmzF/Mq1THfQWGyTuF2S8WY/e0ASqiigvpHFREqk7A1j3NRy3QIqWYMOXE5H6Tc9kbG0Co2eMVYQ6BmpWOn05CpckbANUNu0vpKA+fNL5QBW7DS0jkS9kvE5IStZXF5CzLTxmRrkyHMbSo7G+t5ib05ZxtmsP23Pz2DylgK1zchB6Lg6v76iJ+6ozDpszSJrqQZeSxrAb9CgYXkVFdcYhpUQGgsetp6BbFQxbRE5P0EqiEd37IXt6ce/p5RvP3Iip1MPVpdv4onsD1zh7CMx+hc3jC2kNutAMhWSrl2uSNzLZ0ktIwk/apvLsSwsoWN+DrG8a0vWjanTDGQkE0gwKTSq7wyacDRqya3RyKbvG2RGLO3h96r+4vfpKepryiPMFkD4fwbQ4ki5qoDYjiyx7HrZ3uo/u8hCCUIKFxOxIQ1nVVoKjzcDwnTwruPylaXgLNSZZwgSlgfOABVtD5+iPoxT1hBZhKIkJ9BQ4ONcR5g1fMuaDDuK2VoxKJz4QDE8f9kOtvPv6VDgfrk1Zz2fi93Cru5qmnD7OOHAH+V2FqLsrj7iIwyjOpSilgyJzL0GpsLGnABHWRqZTEeL9gjYfvifCakVNScYzKwdFk9ha/Jjq29Ba249670LxKuZEHwaS9nYXScFgVD1wem8vbNlDyaF4/PPLeeSyU8k7vYObEpq53tXKBXE1+KREl+CTKm16HGsD6azuLeOl5XMof7gRvaEJY4hu0Kga3UCqFZEUEXypZxK2Ft+opfXYugwau+MoNtl5ufQNihZ/mYJgPua3NmN9dw8H/288N1ywkpcnTcJRnY++9+ARz6O6XHhyTdxStgKAypo0CjpGuZm/59MbYuNrXGDl3BnbsAsLu0JhkveGEU2twyjgABACNSkRo7tnyCNsLTtSug/gpwcvxr3PGBNlHN9DBoNoNXXk/bSO2tcm8+VPTebLi9/mjqQKMk1OvnH5En6ffS6Fj5RhWr71I98VqkrNxQncnv4OeSYnVeE+Nm4tZZyvakRkVex2hN0Giore9sHSaTUznZazs3n+x3fTplu4Zf91+F8rJuuJ8CfcdO/hyVM4r2QfBgaubTbUzo4x0RHqvb1Y3thErnUOv3RcwE1n/4s+GeT+rpns9mQR0MwcaE3DOOjE0SBIrAxT/Mb6E5Y9qka3ZbbKheO3EZQarzZOJLHLizZKpd+cL22hrLKcCXU3k3NKA6kbFGyVreiAEQhQfls9D901nxtmrmPDvQWoV7rRu7s/8VCFpxfTNdXghvgGQCVxiwV7ZfOo1Z01FRXQeEEW3RM0yv/tR+ytHFRxZXV8KSmnNPP/0t+myxBcs+GrlO5tRRvFgtOmzAy6FxQw/Y5trHh2DtnLPbBx16DOIUwmeorjuGzBRgD8b6aRvbNt7Nb/3byXMk8Rj9cs5jO3/5ZMk5MvJVTz6bP+woGFVm7Y+HnEoTjsbQJhQE+pwTOX/InxZujSNZb5Sih+NoTRPfwzQzUxgX2/LiejoIOW1gRKP/eB0TU6ukjZ5uJrlVfzl8JneHvy41SOh79+dhFb/j6X5F19mGpb3+/shNmCP93gUvdWwlLH3maAf2ylIZq8OvRG0tge7J7IK79bRMpblchgiAKtGnQ9Et/R9WEZoUfV6IZSdGY5qwgjaW5LIDE8esVIpKahHK6l6MlsgstTSTlUj/GhFUt6Rye5LxXySOBUvnvGq/zlK5dS8FDlJwIdnlwr9ozIVPAdv0piZRjau0ZNj3BGAv6FHu6c+ho/S7qQ+HemkP5azYD3c+qemsyM5G2kqxaqNB3nijhk9+jtz6VMm0D9okRmfWont6W9w75z0unozCZ54+DOIyaV0TlJ8NmkdawPmEis0KB1DK9AM3SCmfF4igySVCs/bJ3MqzUTSYrzcUfBm/x51lNUTEmjS4tDlwqF1lYmWQSbgyq/rLmMmrcLyN+9H32YUuHU5CRIdhNOj6c3x8qlczaTaenhwe75HxXb60OtqMf761KuvPkmfjDudS6J6+I76W/z76/3sbc3g/2t6YQrijB7BMFkgzPn7yJL9fBA9ySSNrejd3UPi8xDQZgtKM44RGKkirG0mGmZYCWnNOKfdaoBhC4xPH0jtstI1IyumpKMPcXHOGsTASkxV9lGPZfS8Hhg937Mu/nklMHQcW2oISOukEeLTiH/3Gp6DuWTsMGEVlcf+YwQ9BYqzMqqIyx1Xuicha3ZO6orn1RfmFCbi7m2Gn4y/VV+oVyAEs4n6cmOY6fe9e9G2zIH5rgq8MkwK3zjSNvUO6r+6LDbRl++wT05S3EqTrLjuumw5QzuJELQMS0B68RuCs0GP2qei73JizEWM0gUFWVyGb5cF03zVSZOr6IyHOY/75xK4l5BR1wSX5vxGRaNO0C6tZdiWyvZ5i66dQffaFjIssPl2LY5yF3aM3zb3whBaEoB7ZNs9BUYGCkhrnVvYEuggHDfR1OohBJxZVnb/fT0OmjTXJhFL8VmJ19JWoclWVCZY+P10ilU+ZKZ6GxiXtwhDoVT+Mu6sxhXt2dUU0KF2YKS4EIvyiKYYiOYqBJIUvCnSZACaZJYJnTz6dxILz/RWk/7dDAFJuGs9SG37B32Yk/DbnSFyTQgn1x4XC7j0hooMoWo18ykbjOQPv9wi3NCaM0tJC0XdIfz+X93/Z0bL/88ujmHxCU9GB4PqstFeLyPG9PexSfDvHV4HKVdnaPmIgHgUA1l/yzg/nkL+GbKanJnPcpP3JeirMlGr6g56gMjVBUlNYXLTt/IAns1u0PxPFw1F/fWvaMa7Vf9GiavlTZdAwKsqyoirXlwD7maEE/bPI3vlq3CZ+i8snMqE1qbR/c+DBDFYqZ+sZvksxu5s2A5c20N/K51EeV/bUava0TqOlnuBPacN4lNGQqeEg1Hmhdfr43UFRZK17Zg1O4bVsMlTGZaZ9iIP6eZWwveJcvUxSRLmGe6UrE0f9REKM449LI8qq5wMq9oH+OsTejSoNcI8GDXHKY7qikwd3KTewNJySYCUmdvOI776hZR+q8Qhn/02rhis6FkpuMrT6N2sUpqeTtTUxpYmHCQCxx1OBQzCkokt76fU20K37vwRZ6YNofD27Moq0w4qq96qAyf0RUC1eVCn1CAur8Go897dOMrBLWL7dyWspeAlCzxTCV+fQ3aGKzZqjU143q5i+9Yv8L3fvAiK4vK2FQ+mbyfrqXnvAmcX7aFU21hajVJ4psOZE/1qMpneL2wYz87bpnCPffC91PXcG/pf7j4B7cw7hvtR00/UlwuuubncFvqf8gxOfl962yM51NAHhpV+Vm/k+KeUi4If4dFF24l9WUbievqBhWsaL1yAtef8i6fia9gqT+D0n+EMcZqjrGiEHJJfl7yIlMtfh7onsr2X0zHUbv1/faid3SS8Ph6EoDMj319JHzUMhwi99k6tDVuHsy8HO1L7fxz/GNs7cwlad9HjY1Rksuhzzo4dMVfUfuzG/aEgnx25+fJvNnL2uxZePId9BQpnH7FVpZWlOFY4yRzdTdi+44RkP7odFw7He/FvTww/e+calPYE/Lz9/aF/KNmAf8AXpvwNNYj1PC+KaGZmxJe5mCpl8/uvJ3kl/eiD6PvfNiMrlpSSOvp6dx2x9P8rep0As9OIG1FM/rhj0VXFRU1OYn55+zmdMchtgbTeHTfHArbhn8YP1zIYJCkJfu4N/4KxHkdfO3qV/n3jLmclrWFL6esol3XeckzhZR3o1RUxdBRtx7g9afnUXNREg8VvM4rZ9zL1d/4NvkvdmLs3v+RjysuF6GphWTdcpgkxcKekJ+V9cXkbO6OSrq9cbiGwr/1UP1kDolNe5FmE8yZzMEb7eQtAeeWIy8aUFwuQnPKuPAbq7jJvYGnPCXcueISxm3bOTZqRigqpsx09n0vF5EQQnZaSdolSN4jqQsnk6rUsaGrkLhl+zCinBOtNzShtLTh2mvBqM3l0mu/haNJkL37o6mDysFaSh/N5/TSq3h4/COkqyaWeKaQeK8LvbkKpa2dxL0WEq1Wqp/PoTTYjfTUj267EAIxYwIFXzjIT3KWEJYK5au/SPoTNuJq+nB4A0irhRlX30q42M/np6zjhymRNqJLg/VB2OQv4o2WiSTt6MYY5sDf8I10e/twNiXzUts0bi9+i79ddwaHSnIpeDURZfU2IOJ6UDMzaDkvl1tT/kmWSfBQVxmWTc4xn4ivd/eQubyNZpnCnxcs4v9Nf4P59kryTSaW+pO5f/dpFDdVRKKcUcAIBMhZ2stOeznfuaCPe7M3sOCSbaywTSN7xUwsK3YgNQ01OYneRaU0nGPwZPabqEJw097PYnonEVG7Lyqyy3AIvaUVWiJpamp8PIbVRHlZA51fddC8tZDk3QUk7upE9HpBVdDTEukc56Tn4j7+L3EDASl4unEW2e+IsWFw6fd/WszklzdzXsZedKmwanIJVW3JTLQ0UqclUNGZQppn//FPNsJITYu0wUAAZU8FhS+PR/WFEHWRLAQ1MQHMlkgHf7CW8OMT+NXN5/HFtJWkmDz05ppJIfIc8t7v3xa9XTqELsl3dJJjgsNhQbjFjmtHE3pDM0Y4hDBbyH/VTPWlTmpKk9//3merz2L95nKctQr2Nkly/QGMYY41DZvRNTo6idttZc+r5Wz+VCvfzn+Td5Im8rwyj0J9Kopfw3CY6Sqyo1/UxXybh0bdYFlDGZnrxp5b4Ujo+w6R2efH1pnD8oJx2JQwLXoXjzTPx7HGOWLRzoEiN+8m1z6dN20zeOvKrfwxayW3L5a86ZxGoTYFkzeMJ9dBw3k6PzvtRebaVF70JuBdlkbu263oXaOXdXEsZCiEyROkojWZ3858ntdTJ7OsuBxPXgrWzmRQwJstYKKHV+f8jSRV5e72OVRsz6H83aoxkQP6PmGNhvYUwukqF7l28I2kHdQVGSQqBg91TsVz0M1Yqx5tBAIoq7chibgzhMmE/5RSQgkmzH06cXuaSXpmG8tnTSPnjC7Ode2ic0GItJdckeDeGFgBqHR52NyRxwH3RuKEhpoSxDshHVuyC9UfWaWomVVCbp0sWzc+I8TusGD76+Mpe70Hsa8qsknoCMg2bEZXahpaTR05v65j5f75PHPtdL439Q02f/oP/PysU1nfVkBmXAtXpezlSwmN6NLCnY1n4F2XQtLadcMlxoij1dUT/2Ibndty+O35n6K3XMNRZ6LgmbGx8klZvY2y6hy+ZrqJ1676PX/MWk3N5e/w7Jkz2N6bw9XJe5hvr6TEbKXHCHH7S1+h9O0u9AOHoy36+xiBAOw8QMnNCdz+vc9w7unbeW7+/Yw/3UyTHgnEJCgqCYqdsLTzjt/Bi08uoOyV9rG1GELT0OobKPlGiGevO5OXF0/mtSkPUWS28FhvLq+9PZuyf45eTveQUFTUlGTkt9v5Yt5a1vSUsu75qeT9vZeS//h5PGUOX1+4kWdO/xvfL/kCSjAU/S2RpESrqaPz1fn8/LJLeKF0CYfOeIg7J43j5brJtLe7kGGFa2Zu5rGUNSQrdnaFJP+35UYK7j+A3tGJHMGOY0RSxhwvbaZ4dSKPTLuYn19s5lfnPcX30laToESKF/cYIS7YfT3y32kUrqpEGwM942CQwSD6oUoyK2vIVFUw5JiKlGt19ZR8v43rDtyOZ5GPq8Zt41r3Ru5I3ku77uc1bwk37jsV7ek0Sp/djdE3BlOrDB29o5OSH2yjOj+Hm069Da7s4CvFq5hvr6QyHMdabynPVk8j4a8u8rYfRm8dm5tO6m1tZNzXhfpCBldP+CaaQ8VZ2UtJ42H09jEa8HsPQ0drbad92Sns+1QWv8teiu/mN7ntkkvYsMfCgqIDOISZKRYVb7ad+Co7RNvo9pP518301E5n3BVf4LlT7+eO5F3ckbzr/SI1ZqGyKhDP3TXnUbUmj+J7Do7KSH1k8nQNHb2zG9uWSsrbMrhnw6f4ZZaC0V+7WA1B+mY/lgNV6O1jOIH9WEgZ8YGNUV+0DAbJeL2OlO1u3s2cy5sZpxKKFyghcLQaOOsCWKpr0fr6xsR08GjIYBCjpp40X4DQoVQezLmMe5MU1KDE1m2Q0hTAdKAyUmBoLOuhaejNrdj7vGAyIb3eiK9wDMv8PoZO3nPNvBGYz5IFE/n1lBf4SfYSDqWlUGzuoN3Q+WHDBcTv7USOoUJPMhzCtaaK4qZMblxzK5580DNCmO1hdF3B6LTi3qUQX6NRXNOO3tk9Kvdj5BZHGHrER9jVhbsqnqSUpEhUGhBhDa2q5qQb4Z5saHX1UFePw2rF5U4Ehz2ylLGrB723d0y4QwaCDAbR6htQ6htIcLlwx7sigZ8+L4bXO7an5x9ChkPoXWNnRjQY9EOVZC210NHl5pvt13P2tL3MdFVzOJjBu53FHHi9lPyG3UMuAjNS6C2tKB2dZNamkZKXSiDdSthuRtHB1hHGdqAZo70DfRSDr6OyIk3v7YVB7jMfY/iQweCY8nWeCIbHE32f4f8oxu79JB2wkLo0hS2XTGHp1IkoPoX4wwp5D21HH6OV9aSmoTU0IhoasQMf3gA+GgOPqNZeiBEjxsmFDIfQGhpJ/VsjqR96/+Qopz42iPrGlDFixIjxv0TM6MaIESPGKBIzujFixIgxisSMbowYMWKMIuJYKy+EEG3AWN+HO19KmXq0gzEdRo2YDmODmA5jg6PqcEyjGyNGjBgxhpcRcS8IIW4RQmwWQgSFEA996P0CIYQUQvR96PWjkZDhRDmaDv3HHEKI+4QQ7UKIHiHEqiiJeUyOcR+u/9g98PXfl5lRFPeIHOc+XCOE2CeE8Agh9gohLouOlMfmODp8QQhxuP8+vCGEyIqSmMdECGEVQjwohKjp/723CyHO/9Dxs4QQ+/ufpeVCiPxoynskjqWDEMIihHhWCFHd3xbOGCk5Rsqn2wjcCfzrKMcTpZTO/tcvRkiGE+VYOjwAJAHj+/+9bRTlGgxH1EFK+fiHfn8n8DWgEth6hHNEmyPqIITIBh4DvgXEA3cATwghxlrRLji6DmcAvwIuJfIcVQFPjrJsA8UE1AGnAwnAD4Gn+wdSKcDzwI+I6LEZeCpagh6Do+rQf/xd4DPAJ4s3D7MQw46U8nkAIcQsYJAbXo0NjqaDEGIccAmQI6V8b5ndltGX8PgM4j58DnhEjkFf0zF0yAG6pZSv9//9qhDCCxQDo7x//LE5hg4XAc9IKff0H/8F0CCEKJZSVoy+pEdHSukFfvqht5YIIaqAmUAysEdK+QyAEOKnQLsQYpyUMvrFgvs5lg5SymrgTwBCiBFdWR6t7IUaIUS9EOLf/b3kycQcIk78n/W7F3YJIa6MtlBDpX8auBB4JNqyDJLNwD4hxCVCCLXftRAEdkZXrEEjjvD/SdEQZDAIIdKBMmAPMBF4fy+efuNW0f/+mOVjOowao21024HZQD6RHtIFPD7KMpwoOUQaRQ+QBdwCPCyEGB9VqYbODcBqKWXVcT85hpBS6kQ6iieIGNsngC/3N/iThTeAa4QQU4QQduDHgAQc0RXr2AghzETa7cP9I1knkfbwYXqItO8xyRF0GDVG1ehKKfuklJullJqUsoWIwTpXCDFmb84R8ANh4E4pZUhKuRJYDpwbXbGGzA3Aw9EWYrAIIc4GfgucAViI+On+KYSYFkWxBoWUcinwE+A5oLr/5QHqoyfVsRFCKMCjQIhI+wXoI+JX/zDxRHQZcxxFh1Ej2osj3vMhRluOwXCk6euY84UOBCHEqURG689GW5YhMA1Y1d+JG1LKTcAG4OzoijU4pJR/lVKWSinTiRhfE7A7ymIdESGEAB4E0oErpZTh/kN7gKkf+lwcEd/6qE7bB8IxdBg1RiplzCSEsAEqoAohbP3vnSKEKBdCKEKIZODPwAop5fDtbzxMHE0HYBVQC3yv/zOnAouAN6Mo7hE5hg7v8TngOSnlmByRwDF12AQseG9kK4SYDixgDPp0j9EebEKISSJCHpGsmHuklGNjs7pP8jciGTsXSyn9H3r/BWCSEOLKfj1/DOwcS0G0D3E0Hd5LKbP1/2npvz/iE2c4UaSUw/4iEiGUH3v9FLiOSFqMF2gi4pPLGAkZRkqH/mMTgXX9euwFLo+2vEPQwQZ0A2dFW84T0OEW4DCRaWwl8O1oyzsYHYBEIp2El0ia0q8BNdryHkWH/H65A0TcCe+9ru8/fjawn4j7bQVQEG2Zh6BD9RHu07DrEVuRFiNGjBijyMnkS40RI0aMk56Y0Y0RI0aMUSRmdGPEiBFjFIkZ3RgxYsQYRY5Ze8EirNJG3GjJMiQ8dLXLY9TejOkwOsR0GBvEdBgbHEuHYxpdG3GcIs4aGamGiaXy2WMWM47pMDrEdBgbxHQYGxxLh5h7IUaMGDFGkZjRjREjRoxRJGZ0Y8SIEWMUiZrRVeLiEFYrKGq0RIgRI0aMj2DKSEeJixtRuzQiO0ccCzU+Ht+p5dSdq4IEk19g6RZkbPRjqWjF6OzC8PlGW6wYMWL8DyKmT6RzajyeAoFhloQywog+E7Z2BVeNJHl9K0ZVHTIcGrZrjqrRVePj0SYWUnMZfPO0N1CRdGpx7OvLYFNWGfGH84mvzcZR14eoaULvGqvFlmLEiPHfgLfASfssg7nTD5Jo8XOZewuNmpvNnkJW1hfTl51Oyq5kHHUeRHMHesuJ7wQ1qkbXKMuj/uw4Nl1wN3vDccSLIAlKmMQkBWu+iZ0hlT81ncPGraUUvOLAumYfhj8AxohuWRQjRoyhIATCZEaoCqgq6DpSN5C6ftK0WcMskHaNbHs3DjVErqmHyZYuLoqrQs1YjmOOmTua5rNkzUyyV8YT93InUtNO6JqjZnTVlGRap7nw54Y5/b47yHnHg1QVQm4LvXkmxIUd/Hz8y/w57xUSCiy0XRpk4fJvkP+Egn1zJXpH52iJGiNGjAEg506h+ZQ4eqcGyc3qpL7FTfxmG8l7gtj2N6E1NEZbxOPifGYDZc8q7FJUUJ2snXszQbeZsEMhmCDIuKaGB4qf5mdXrOSBM6fyTPLZpPx70wkZ3tEb6eoGqZu6cR+yYalswujoBCFwmE3EbbVhrHXzq/LP0TpboXR2DX8teponFvyD+8oWsX7lREoe7UTfc2DUxB2rqMlJNF4/jvgaDefedozaBmQwGG2xxhZCoEwuR3PbkUJgaepFP1gBsTKmw4OiokwqpebbOhcXr2VOXCUTLM14ysxUz01hjz+HlS2l9D4/j8wltejNLSc8OhwxpASpIw1A0zBtPYzZZAJVQZhM6OtTOP+c75C1uJYfFC7BeVuAJ3ouJGFl5ZBdDaNmdKXfj6hpxFyroH3CV9sDzS0kNCbjaM2jqaaAs+d9nd+f8gxfS1+OtkBle9948g6Yxu7N60eJi0NJS0HardDagd7eMaznF844+ub6CC3UaKxOI74inZQdPpSNe4bltxFmC4FzpxJyqlg8OvbV+zE8Y3ZjiY8gzBbUZDcdZxfSOlciEkMIITHaU8hZnoRrfQ1ac8vIXd9kInDOdLQ4BWeND3YeHFqHqKiYsjKQfj9Gn3fsdarSQAQ19H1unm6fw9PWmVjjQsTHBViUdYiZcVWcWnSQu68+j8r0fDLWZ2LfWoPe1hZtyY/LJ5715hZywuOosebxZ8vZPFj4Cn+87CwcTdmYenoxAoFBX2PUjK4RCMBxBNTbO1BWdpCxOY70DYX86AeX8JvJz3Nr1lv8/aIwzQ+lozU2j21/UXEu7VPdBJIF7kMJ2Jb2DW+jEQJXXICHpz5E2/Q4Hmubz5oVkyjyl6PWt2L09g79ekKgJLiouVySlN5JU1MC42uyYO/BMT9KFCYTalY6numZWD7bwivlT1BijjzeleEwl6R+DSWch2OjMWKNX5hMNJ1mwij007vZRW5TClp9w8C+rKioSYkIlxM9yUnHOBfWHgNrZxBThxc6e8aO0ZISmlopflgHIUAIjHg7/kw3L8yfx9JJZXy2aCMPlDzJa5nj+X3yBRToeZjfaR/zz9GRMHbvJyd+KrsspbTn6fxr7kPctuKrZFQmYQzBhTImF0cYXi9y827ybuvj9m1X06a7+GbGUlrOz0N1ju1CF4c+6+aC21fy9rfv5vzfrEDJy47kIw8Ten0jmd8O8rX9n0ZF8u+81ez67J/J/3slTZ8qRZQXDvncQlXRynL44+n/YcvMp/n16c9SvzgZYTIPm/wjhZqbTf1luSz62RpWTX6BiRY7VmHGKsyMtzg4dMZDmL/VTOO1pQjTyIw1pG5gaxdcUr6T8DwP3fNyBi5/ajJN15Rz4M4kzn14HY/86vf87J5/ctWDb6P83UvD9aUIs2VE5B4Kem8v+uEq9EOV6AcrkJt3Y3tlI4XfW0f65zt45etncc2uG7kgbh/3XfAQbTf7UZzOaIs9ZJRN+8h7K8DPGi9gnlWnp0wSKkwb2rmGWbZhRaupw77MyV0V55Oh6oQu7Ea4hufG6YtmUPPzeYzfYsK8IpOK38+l8/PzEDMnnth5XTpJJi8JioVFzr3oyU6EZfgai9Q09MpaEr4Q5I47v0zR2zey1O/i91nLeeL236H90UvzN+cPybAoDgfVFzsoMHWgS4NmLYHECi0SjR7DmIoK2PezZG776rN8P2X7++//sHUyE9Z+hqK3bqJJ6+PpsqeY/Zkd1H97zojIIcMhsv6+nX3XFlB0Rw8JKypRS4uOnmyvqJjyc2n+5nxyX/Fw7+33sn7hvdzsPkCxyc4Cm8bn4mv4T8kLPH/bbzn4z0kYp01Dsdk+ea4xhN7RiXn1LlI/186Zb9/K/mAmN5evpP3qSSPW4Y00MhzC3N7H6p3lhKVO+qRWOifYh3Susf0LSImj1aCl24VDqCzO288ee8GwnFr1hhG6jfmuQ3w2aS2b0grZcloBW1pyCK6bT8oujbiDHcim1gH7NIXViivDQ5G1hYDUqAunY2rqQvf7j//lwWDoaI3NpC1XSahO4YebbqT8uv38POcVflH4Iv+47nTWO+aQ/8B+9K6eAbljTBnp9M3O55rz3yXfpLMrBK80TcG1swVNGsMr/3AhBIrdzoGbM/jCtOVcEFeFVcQRlGHO3PUpet/JIHNLEEU3WGD+Ovee8gQ3pa6i7QInoeeLMKpqhz1GYPh8KHYLLYvS6Zyhk5jZS3fbeJLXmUnd3I2xYx8AanoavQsKaVwguHbhu/xf0jpyVDOqsFCvBflj61m8cXACNFuRKiycu4dfzH2JH3EpaQXTcD+7fUj+xFFBSmQ4hN7RSdEThTyQeBrfmLCc7jJIVlUY43GZoyECISxtJgwMFmUc4tmcdNJstkHfhzE90gUwew3CQRNmoTLR0RDJBxyGXZFNbb0kHjL4+e6LWO8v5sy4g/w2620en/JvZl6ym9orDGquSqfzsknoZ8xALSs+9vJAIVCT3ExIbaHA1EWPofNOzwSMzu6RC/4FglhrOsl8q4VdS8bxw7pLCKFyZ9YbTL5oP93nlKEW5R13WqomJuCbmkvtBfDt5A04FDOPd82lZnsWen3TmPXDqQnxBOeP59IzNvKphC24FRv1Wh/fbz4F76sZ5LzeiWnZFpRV20l72cp9DYsA+FbumzSdk4Hidg/vck8hUKZNoP68JLQLurlz0XM8Ne1B7jn9CYxLO6k7z41aXoIpN4eOxcU0XKDzhUXL+VX6TopNdvaF4a9d5dx04DMsfW0mGc9bKPmPl+Kn/Kx7czJmofGF6WtoOVMjNH/isLSDkca8ZjfhChct4QQspb2MxI7mR2QkrqPpWHoFOpJZcVWEkgxEnGPQpxnbI92PYRY6KMPzY2pVNSTUN5G0Oo17vnYRe87O5sqkTZSbe7gn5w2suUupOVNjSd9k/r1/HuqGdLKX2zE1tGP0epCahgyF3jdIQlXRclM5M+kdCk0qO0MW3jwwnjJ9ZNLcFJsV78w8vOkmXPVhcu/eSFXLbL5zlZvXJz/CfwqXcdXNCtUPlZL+Vhitrv6o5zJKcqlfZGbpBXfjVp0cDHt5dutMil8NDevyx8EizBZEfzAMw4gk3vfLI6xWZEE2NZ8zeCF9DU7hoFbz8XTvdFb8/RSyntn3wYpGKXE9tZ4Dk+bx2Hnz+WXmCmZ9bgd1m4pQvN7hWXYuBGpiIoeuTeAXlz/JYkcDOpJGXeV0ewfrZj7Gb/Kn8ow4A0eTpOzL+7gv8y1mWi0EZZjKcJgfVV/F4fX55L/qJ//dtRHRASEERfvi+X7JFdxzypN8b56H36jnMW5rPHpP75jtFAFkMIitTbDHk8l1pVtYY049bkD9hBACxWpFSU6KtFO/f/gGPYaB2j9pzTV1glNDDMHVM+aNri/VhCu+DwBdDm/vJcMhtLp6Cr/fQM09adxV/Fk6x9vpmKUzb/Ihbs16izuSKrhjfgX6PIP1X4U/NpzL1p2TcO9QyHi5EqO7ByMYRFgstMxxMc7aiEOxUKslELfNjgyPzChXSYin/vowj829nw4jjvvOPY/kx7cSqp3EzMtvY99l9/Js8VI+/8UgGzInk3vn0Y1u7eJ4Tlm4l2JzxF+++I1bKXxOoi7fOiKyDwQ1Pp6+RePomGhCt4LJD856g8T/bEZqGsas8VRfbGfroj+QoNg5GPby+X03YP1DEilvreNIDpX0LTpvFo/n3uwN/CN3DTNmTiGjKx0OV524vKVF1FyVzo7P/AmHYuHuzsnct/ZMyv8RoPoO+O305/h+yi6+evMmAJIVO6qw0KT18YuWs9n4wHTSlzZSWL3+k0ZUSvTuHspureeWX36Wb536Fm+c8Rcu+u7tlPz+4LCnJQ439jbJvrZ0bsx4l7WWrMgodIQ6CrWkkLrLM7j5/17it8suIu91A+urm4bn5IqC3m9jvdKC1AQMId4xurUXJpThKXej2QUJz20bUGqTL11Q6I6MWGxKeGQEkxKttR2110PaATvp7zjpis/gmxO+Tvs0wRln7OS+nFVMt+j8If9FmnOsNJ+bwBtfnMLm1lzaGhKxtJm49qKVTDb7CEoz+/zZpG4PjlgQSm9rJ+O5fP7v8C0EU3XG91YgwxrWDQcpb81masc3+Ov1D3B7xlv8/bIA7+jzyfn12k+cx3PtXMYtPsTPspfgMyz8qn0mhc9JbJsqjmi4RgNl2gTqzk7kS59/lQm2elQkOoJmLZGfXXgRcWvi6J4S5mvz38IprDRpfSxe9k2yXjdjXbeHo3mglbDEMD7ouMPxAmkbnsySYG4iEy84gFWYuKbyLPYuKWfCUw0YLW2I3dPYPS6XS+IOkKxEgi+qUPhTVwF/3nImhQ8L0nYeRu/uOaYx0js6KXk0hz8Gz+OUiw7z26se5a5dnyFptf2YM5loY+kzaOseWtBpsAiPF1eNQYGlHWdOL76URIYvdwhkv0O2WUtA+FSkb/DxmlEzuorNRuv8ZPzn9+KO89OYMZOslT2Ig7VHDVSpbjd9xRpnJB8kLHX2+bNBGyFTYOiRaabPB+0dCLMFW8YUTH4LTf54AByKhTzFQp4JsPqYbV3KgaR4dhXkUhFI5f8SNxCvONgfDrKhswBbRRvaCOUUS00jYUsTjkY3oUQLss8L0sDweFAOVpP/moUvFnyOn855mc8kr6X1IhdNu+cQt3I/em8vwmpFKc6n+6o+fpy1ihRVZXPIwnMvLqBobw1aT++IyH08TNlZNJ6aSNb5tdyUcAiHYuEtn5luw8E0az0/n/Ey/8maw9Xuaj4VvwNVOLmj/iJSVltI3NiAdoygZ8ilYrN/4EowVIYlqqGWFNI8xcp3M1bxqs/J7jfKyV3mQauK7NiiBiEsI75jVUQu+KeuAu5ZfS65b4B1U+SeHBdDx7y3huSt5dw55WL+U/wyt52lYW/PwFzfMOpuBlNBHqH8ZHxpFhACk8/AubsZvanlIwMqYQD66PhyjV4Pibs6+cazN+KqAve+vuE7udlEKEGiIggYZoQuhjSoGnajK8yWIxa8EBYLngK4e8oLXBLn4xsps3nHOpuMhDJsFa0Y7Z3IUBj6I+XCYiEwu5jy8gYWO/fgkwav1k8kNeAflYdLKcqjfYoFvdxLtqObfeEwAWlg9Hd1XmkBElCRnB53gM8nHMCpRKbn24M5HGhIp7R+14jKqFXXIqprscIHozshkJqG2HaArJem8UTOKTxQ8hR/y1vCzCu/TnF3Meb99QiLmebTknlo5p+ZZJbsC6v8ueFsCh9vRm9uidoCFN/kbHrn+nm25D84FCc7QwF+fvgKevw2bijdwB1JFVzrehMAXTpo171sWDWeks1daNW1xzy3N10hJ7Fn2GXum5hK7+QQp9h6uerANeS96UFu2fv+cfkxw96qe/nz5jPJfR3sL20c1IxC7+jEfdDPnm0FOEotfHH2ap7ZehYZaxwYXu+w6KPExaGkJCHNJoSmYzS3fhChFwJhsaAU5dEyP4Xu8RI1N9KRhXxmshxZJG7kuPdipDB8Pth7kJLfJGB4/UjtY7NjIRCqCkJBccaBqiCDIWQgeNz4hbSaCadqKCh4DDtKeGhukmE1usJqRcnPgY4ujN6+jyih93lJ2WFwe/HVnL/wX/w5axPrv7ieP190NptXjSP/1WQsDV0QCILJhJbpJv4Hdfwy/0UmWuxsDwaRz6ZgdO8eTpGPyoGvpvDdxS/ypYRGegw/89Z/EX+7AwwQusDSFWlJUgFZ4uW3M5/nsrhIr7qiexyWw/bRX7KsqKjOOES8C2m3Er+3k30Hs3klYzw3J9ZRee6DTE74NNZXS3DVhSn/3H6mWkCX8Memc6n/ewkJh9aPrswfk7/6MsHXp6+k2OxElwZXb/gSufebcAR17vviGdyxuOL9j/caAZ71lFH8TC9U1B339L0Tw3wja/MHl9NA6CfYgQtBx0QTZ0/cgSElzW/kktdU85EZjqKDQWSkF5Rh/to5h+J/GJg27zyqK+RYqN4Q1o5I1PzWpF38c9wZZJTmw/a9x/nmAFBUtBll1FxoI5ykYeo2UfKYA3YfAkNHsdsR+dnU/tLCUzP+QKFJpU+G8RiSApOD6e7rCTuycT/0gdGVKqBKAnL0Ftno3R/rXPuzGdTEREScA+mw0TM1Bc2u4GgJ4zjUHpmZHM2ICoHhtFFQ0IoqBNs9eVi6xJCCsMNmdOW8qVRf6OD5z/yBi1+5ldLH/bB+5wcfMHRcL24jYXsOUz79dZbc+FumW638u+AtPHlLaLtOsNZfREs4AbOiscBxkCkWHauw8kBPFr9+90LGPb1z9AqcSzCkoCLcxz1tiyj4ShPS39/bSwnGB83Fv2gy3zddxmXzHwNgd2cGrupRjigrKq1fPYXgol6+On41U+01pCo+MlRwKlYgMr1dN/tfrJ3sojKUxucTqrEKM62Gl/ZAHBZPFPNxFZXwmdO4fu46bkrcQ6tu8NPmsyj+qR+jshZj1ngU8wfy6dJgZSCNv/7rUnL2bT/uc6Gmp+HO6GWarRZdmmjVfTjrDUT3idWVMGWkExjv57OpazgQtpLzdjfGhwNbQhCe5WFOXKSz8BghnnhjIWU1dWhDjOILfwhLd+T/DsWCdOhoLuuw5H+q8U6y7j7M7zPexiZ0Humay6o183DsU0FV8S+aiHpbC2vGPcLMVV8lfpWd1K19qJ4AvX/U0TSVoPujroTuYpWpRdX8qeps7P7WkZupKiqiP7vpvQGPGh+PLMym9kI34Sl9LCioZEHiJkotzeSbfKhAt6Hwet8kHnh+MUW/24Pu8XxCRsVqxZ9q447CZzCh0uBLwDxEz8WwGV0lpGHuE2wK5OM6rKJ2+T4xbZLhEEZtAwXPWbjvkoXckrKKPJMDl2IhQVFIVSsI9yubpFrpMcL8qn0mT6yZT8mTwUjDGiW/laVHoUd3oACKkKBpR7y+MFsIJqqcmX8IgKpwHy2VKZTt6GW0E3m82ZLTc6v4VPxenMLMDVWX0OSNJ9nu46K0nUyz1TDJrHCKrZdp1m6sIrKkOkGx8P/yX+fe289k98x5FLzsQaloGL0i8kKgJsRTcaPOr+K3YxMmNgQcLH9lBoUNu5FhjVCCmfE5HwSLKjQ/T7eeRe4rrcdffCIEnlMLOS1rK+VmAw2dt30FJBz2RqrdnQDSFUdCgo9ctY9lvhKULg+6brx/XcVu5/SCw5SaO+gzVLYGE8leqWF8fCQ22Ot+yMI6k3z05cQTf0Jn7D+vbrC1OYevdn+axsoUUjappG2uQdPCyLlTaDzNxJ8L3mT60lvIe0ohbl8DRlsHUtdpPDgVEsOYPmb9Q25JqauV53bPoUxvGgYpP4mwWum5YjodkwWay8BZpWLrkPTlCowpHr404Q0m2epQhYHXsLLJX8TfegrItPVwRvw+LnXtpOdSOxufm4JyqOYTnbiSnIQ3w8RkSzuqcFLT6cbVNbRByrAZXbW9l6R9cfxszSWkeCS+YjemrBmRY34NU0MnMhCMVChq76IhkIhPqhwMB3i6ZxZbuvNItfZhVTWUfnO1rSOb1u3p5KzXUTfsRY5ioMDWBq0hFzYB4+xNHEw9BeH1f8Lvo9htBBMF5yZG/Lcr/UXY61WU6sbRjf5LA3uroCXgwq3YUBDsWFtKXIPAY4K7cgsQaUHuOeVJTrN1kaZGDO5zffFs8+WjCoPzU3aTcb6HtY0zyPCmwCgZXTXJjX9WEbdPe51yc5B6zeDFrgXkLPdj+Hyozjj8KSYuS933/nfW+gtZX1FI6YEBpLUJhbZpCrOcVTgVG126j6ebZ6O29Qx5tPn+qUNhej3x7AhlUBtKjvgG+4MrwmKBojwWJbxJuqrQbWhs9BUTt7PxhFYpSrPp/dQlgAR7AL8r4YT0eP/coRCscOMLQeHhELatFWjtHaCotE91YBvfTavmIudFFcea/WjvBQCFgCOkdKrx8YTjdVLMfVhbVTBGpg0rViudEwSzTt/PnMQq/n1oHm0tTnIL2vl+8Wuc5wjyQE8WT9bPpqYpGdFuwdamsDZbp3u2g19mvcU1CZtZ55yN6QhLlY2UBHzpghTFgi4N/M1O0luH5j4cNqOr1dbj7OmlyFNC0zxB+xyB4oz8wLLDQeqWOKw9OkpYIlXBVMd6HELnNe94Hl61gLw3DFqSTehmQAASkvd4Sdi7B7139EeNCVVhDnjSMacJzow7yFNF52NrbvuE0RUuJ8FEwQxrK+Dk2eaZOOvl6G81JCVZy7vYNS6PlkI/6aqd1K0S97s1kWLSQmAqzOfRR+dTlL0Ep9mg1wjw3c3/h22HA8MC5pldvD3zn8ydMI2kAy7Ufce/7LCInplG/VlmPp9QjYKVpzx5vL57ImWrt0Tue3oKfTmCK1y7ASdhqfN8ywxcWwaWmC7MJuJntjPO2gSYaTMk+zfnU+atOO53j4fR0YV1dw53J59LusMDweD7wWDFbqNrSiJTrQ0kKA5qtACbu/Ij9+MEBhDSbiYc/8H3TYrxiWDdkM8dDJLxpw9SC98bOCg2K13TdC7MruSPB84m7aVN6B/TwZHrIRxWI9kK75GbiZoYwqGEsPTy/m8z7JhNaC7JrIQazonbx9b0PKrtyVycvZPzHJFMil+vupCCF2DchsPvt8/Q4lmsTivCkyGpCCcjwvoRB3f+bCe+fA2HYqFL9xFXpWKrahvSwGrYjK4pK5POhXn8/dd/YqLZ8n5qzPtcHfnHZ4TYHRZMMkscipPz4vbRtCCRl2oWkLnOh+lw40eKA0crV9T21jb2nTuLp9LGcbVrP60zLRTsjPtEeluwLANfnkamGglsVHUkkdQXHd+osWMfyVvm8f+mXMRjBSvwXNuLrSsLc2MTitVKzTVZ3Jm2lCKzmWrNx5cOfZqy2xrR2zpQSwpobUrjlNZbGX9/F7KydkhBnqGg9PSRuN/NjhA0ay5+u2kxhY9/cLxnehrhyV7yTJHskDUBM/s2FFL2XA3HG2soNhuUFPCtkjcpNYXp0sMs85ZR+ljvCU/xIVJ/Ne/PO1CeSMKbmQndH8QxZFjD2qXTadgIyjDdho263gRSGPo+W8JqxZ9uRy/8YKTc5bNj94zssES4nKTndRJnCiKXJn2y0xAKp2TVsPxgGfHdHxzrmegmN7WJTi2O7Lc60Ecqb72jk3F/auS1F8/gqdzFpCyvxZYXz9++dAbfOifi+nNvM+E42PTRet5CYLFomAX8q3EBptpWNO9HXQvCZKJ1ppkvzn8HgH/2TMZ9WEPWDW1njOELpNmtBBMF481mVKFwQ81CVu8qJ67CDAICKQZJ4zu4sXAtN8RX4VAi9QDyTHa+nbyB87+2g7Yvx3Pb0k9T9EwupmVbhku0oemjaWS+K/lj6tl84YxKzrtyPTvWTsPc6/lIao4/1YI50f9BJ7MlAWdV96gZrI/jqg2zZncpFKzgpxOXcFfm9aQkxGOU5nHldSuZb2sBLLzhHU/43gzMndvB0JFNraStlKStEhg19aNaOFtvaib1ZT+3+r6OoknKqr2IfVUYRHzmbdMF14z/wI3wzV2fImW7jKS2HQeREE/bbDen2euIVxy847fyYOWpJO+rGLYlzobPh2wIorS0feS+Gz4f9lV7+eavbqb37Mgz434tDuTBIV/Ld/5U6i/XeOPUvwJxtOte+qoSyNo1ss+cEAIh+meuRxlVezQrtoM23Ac+aB9NCyRzHb283TSO+LqRreOh1zdibm0nebsZvc+LqdeDc+ckvj91Bnelb2fS5/ZwsG8CSV097490e/NMZMX30qxb2bEvn3GePZ9Il2y7cTa5Z9TyJfdWwtLG37aeTlm9b8gFh4at4I3wB7F2S/aFw+jSoC9sxdZoJvf1TnJf66TwxQCmR5K55+lLubtjGmGp02P4We638aPmRewPZlEXSkb1Kph8I7TybJDE7+rAutvOuoCVG5PXUHeWFX1qyUc+05uvMCGrGV0a1Gp9uGoMlPbhzwUdKPZ6D679Zlp1L7NtjXRMlbRePYFD18VxfeJG3IqNh3vz+f3mc3Btqn8/j9Hw+pANzRiVNaO+U4HUNPT2Dtyra0l4txpxoOb9jk0pysNU6uHyhEgn3GcECG13E3/YO6CUPBHnoLscEhUTqlA4EMyio8o9vDpKGVma/PFGKCWG10v6siYynrSR/pSd5PUntpusrSWI2mRlrT9SN/mBrhk4qxVE48gWOJfhMB09caSbe5GLulAnlH20TrQ02LGyjLStYcw1bZH0xYnlTJtaiSIkDZUpI555JPuD3Xp3T+SZ6vOSti3As8vnUhHu45aMd+i9rI+Gz41HTJ+IGh9P5zSdRakHadTcJO762M40QmDKzqJ7YYDrsjeSoNjoMgIkrrOitg29jQ+b0TW6e3DWBfhNw/n0ySDjXC0EU3UMmxnR0olp60ESXttD7lte1rYXEZY6GwLx/KH2XN5+YwZ3rr+QP6xeTPIOgal+bKwlN6rrSNmt8Zua8yk0qUw8/TDN8+Iw5eZEIu7JSfQVa5yXuhsNnVf6xuOqD2J0dUdP6MZWkg6E2R5MJEWxMHVWBeLSDm46ezll5ji2hQzu2buItLcsH/Ut9q/Ii+Z2SFpDI1pzy0dcOOEMFyWp7UyxqOjSYEfIQtIeHbVmAKNckwktxUXipA7MQiUsdXb25eCqGMbKYgNAq6zG/tJGHC9siOzVdgKYDtWTtsXgF5su5E9dBfxj4wLcB8Pond3DI+xRkP4ARr2D9rCT3016lobFKWjzJqJMGYdaXoJaXEDifjD3hpGJLsT0cTScm8xNWatp8sWTsD8KW20ZOpbddeQu1flN82IKTCH+NO0p8i+vpPbCBPoWjePUaQc527mHXt2Gvd34INCnqKhJbjoX5vGZyRs501GJT4Z425dH2sZejPahZ70Mm3vB8Hox766i+s/j2farlfwwdTPXXriR304/j4N/H0/S7l50p4WWmXb+WPAYVmHi54cvxvtyBgX3fbQmwFiptimDQZyba+n+Wz4771J5rOhVbrziPPao48j5Ww99C0pYMHU/18Ufpscw+P3Gcxlf2YI2TCuDhoLe1YXjcBcPNJ3O/MIlPF/y9gfHpMFnNtxE2jN24p6L4iKIQaAEdboDdtp1Pw5F5de1V5Cwt3tAmwKqKcm0lzt5aNIDWIWdWq2PdQ0F5KzxjHpgdrjQ2ztwPtdN+dJ4XjrlHCbsqEPv7EKO8ApCw+cja7XBk8mz+cm5W3jim7/nz61nsrahkL7mJEy9KlqCTtscK9JswZ7i477p91Ni7qXycAbjVkXH5aa3teF4N8je303imZ/VcqlzHy+UvIZWovOUJ5NLnXU4hIVmvY/26YLEt+Iw+kBNduOblsdl33+Hr7h3kqA4WRWAH757OeW7d2GcwExpWFek6d09xD+3mW+5v8zMz+/kt1lv8+/8d+i78zVWBtJwKX6KTD3kmRxsD2n0vpVB7usNY8bIHgmtqZn4V3u5zXwzZ31nDb/MeRnl5pd5+rPTmRe3mslmHx7D4PGe6ZT9NYTeOgb2sWppo/He8Wz4VRzzrH4ciuX9VXUlvwhiHNh78hidDbswHpjDgvm3kzO5mdCDGSQ2DqxcZs+pBbQvDjDREim2ckvVVairEpBbNoykxCOPoaN3dWF5a+uI1fY4Eo5Xt1LaOpEJPV/nkUvu47dZy7Blm9ClxMBAQXn/X1UITKiUvH4rBS/K94u3RwO9txfnc5tZcmgB9152MUlzm/lywSqud7WiisizcZ7dx+zrf8efFs9jvycdt8XLBUlPcVlcN6qw87gnmZ9uuZgJP6xHO0HX1LDXXpCaRubr9WxWp3LKaSX8ZMYSrnd1sMjehooATGwKSj7/8K3kr+zBaBq53VmHC8PvJ2l5Ne9wKk/OPpW8SU3MSKoj3hnkb13TeWT/HFxvOEnZvxsjFL36s++h9/bhXlXNLQ9/GfusDkyqQffOFAqW+JFVlWN+R+WPICUJa6pxHXCjud3EHa6OrBgaACGnQkJ8xI+4MxTgwKpCCtb3je2NTQfDKOshNQ3TnirK/p3NN3ffjKcQQhlh4tyRTIpwWEUaAl1TMLxmHDUmSld4IxlJ0a75a+hwsJrCJ7MIrUzkb5lX8ds8BW9xmJTMHqakNHJ1yiauTNyMmihxKBqpisDAyo9apvDU8vnkvaWjt7WfsCgjUmVMq6kjc7mdrq4kftR2FfeVfTD6C2kmOtpdlL3mQTlUhz5Wtxz5MFKiNTXjfiuMo7mAzsPZLMnK4pWiyVDjIGm3JHlF7TErXI0qho7W1Ez+66l01CdhKFC42wsb92CchAZHa26B5hYUBud6cjaEqNubxK8KynmmajoZG3XUww1RS0P8b0Dv7YWdHtKaU0nJS8efYSeQGFkLp2gSYUT+NXsN7JUtGFV16FEshP9hDJ8PDhzGVGHC7XDgzkjFW5aMNz2Z9WkpLCsYT1yqD5c9QII1QKLVT3VPEt2bU8lbq2HfcBh9GAYsI1baUd97kPj9Ku4lcRjFue+H7IRmkNbZglbfEP3eb5Do7R2YlnWQtizyt6kwH6PlEIbPNyZdJHLTLpKGqX7zyYh13X6Kuwp4iDPJWqXh2FQ15gt+nxRIGfGpt7RiA462RGWsdm5S0yKdR28vtoMVEfkVFTU5CRJdGPF2giluapJNJO7zkLh3KzIYHDZ9Rrae7v9v77zj46jOvf89M7NVvXerWcVywb1him0wwZTQQriE8OYSUiAJJDc3yU3eNNLe3IRAKEng3gRCAgRIMM0YiME2scG4FxVbki1Zlqy+Kivtale7M+f9YwUB4yJZ0u6azPfz2Y8+2hnt/h6dmWfOeZ7nnGPoIeP2VL/3loSI1bBONO+ul2oSnRgeD+yqpnCk5DtanYBJFGDo6F1d0BUalVtHXpPRLYz6jSlNTExMPkqYTtfExMQkjJhO18TExCSMmE7XxMTEJIyIU61RK4ToAqI9W5QvpUw72UHThrBh2hAdmDZEBye3QUo54S/ABvyB0D9mANgLXDpybDGwHugBuoC/AlmToWMSbagAdgK9I6/XgYpIax6LDced931CidqLIq15jO1QMKJ78H2v70Va81jbAXACvwW6gX7gH5HWPMZ2+NRxbeAdaZd5kdY9xna4HjgwcqwGuGpSdEyScTHAD0duCgW4fMSQAuBSQqvrxo9cbI8Ar0a6QcZoQ+LIT0Fo87E7gP2R1jwWG953TjFQCbRGqdM9VTu863S1SOscTzsAjwNPAWkj11NUOavRXkvvO/czwGFGRtLR8jrNtZQDDI/4JwFcRujhkT7hOsJo8H7g2hO8PxcYiHSDnKkNhGqdvwR4I63vTGwAXgVWA0ei0emeyoazxemexoZywA3ER1rTmdpwgvc3Aj+ItL4xtsMioPO4Y13Akon+zrAk0oQQGUApUH2Cw+ef5P2o4kQ2CCH6AB/wAPCzyCgbPcfbIIT4BOCXUq6LqLAxcJJrqUkI0SKEeFQIkRohaaPmOBsWEhru3iWE6BZCVAohro2owFFwsntaCJFP6J7+UyR0jYXjbNgJHBBCXCmEUIUQVwF+Qk55Qpl0pyuEsABPAI9JKQ8ed2wWoXjiNyZbx3g4mQ1SykQgAfgysCcy6kbH8TYIIeIIPSjujKyy0XOCdugGFgD5wDwgbuR41HICG3KBGYRiudmErqXHhBDTIqfy1JzqngZuBjZLKRvDr2z0HG+DlFIn9KB4kpCzfRL4gpRy4tdpneSuu0IoVrUOsBx3bCpwDPh0pIcYZ2rDcee4mIT4z2TZAPwK+P77zjlCFIcXRtkOmYTCDXGR1juGdvgaoVii9r7zXgLujLTeM2kHoB7490jrPIN2uGjkHp4/cnwB0AbMnujvn7SerhBCEMoUZhCK+wTedyyfUMb/x1LKP0+WhvFyKhuOQyGUFMwJl7bRcgobVgJ3CCHahRDtQB7wjBDiWxGSelLG0A7v1j9GXf35KWw40fA1KleCOl07CCHOJdRb/1sE5I2KU9gwm1DVyE4ppSGl3AFsI+SMJ5ZJfJo8BLwDxB73fg6hzOZ/RvqJNw4bLgbmEMo0xwP3E8r+2yOteQw2pBDqGb77aiZUVRIbCZ1naMMioIyQk00BngY2RlrvGG2wAIeA7xFKyp5LKKNeHmnNo7Xhfcf/B/hTpHWeYTtcQChcNXvk9zmEer6rJlzDJBmWT+hp7eOD9XufAn7Ah2srByPdGGO04RPAwZHfu4CXgVmR1jwWG05w7hGiMLxwmnb4N6AR8BAaCv4JyIy05rG2AzAd2DpiRw1wdaQ1n4ENdqAPWBlpreOw4csjD8ABoAH4+mToOOWMNBMTExOTiSXqYl8mJiYmH2VMp2tiYmISRkyna2JiYhJGTKdrYmJiEkZMp2tiYmISRk65MaVV2KSdmHBpOSMG6O2Wp1h707QhPJg2RAemDdHBqWw4pdO1E8MisXJyVE0Qr8u/nXIxY9OG8GDaEB2YNkQHp7JhcrdgNzGZTIRAsdkQVitYNERcLHpSHMIwEO0uZL8bw+8HsxbdJIowna7J2YOiothtCKcDYbGAzYqeGk8gzkrQqeJN0xjMFQgdkmvjcbYOoXX0I1296G53pNVPGMJmQ4mLRWgaRl8/xnAADD3SskxGiel0Tc4KhMWKkpyId24+bUs1htODxKZ7+GzpFhY7DlNm8ROv2FFFKDfslwH+MpDD/XXLsfxtOklP7kAGgxG2YvwIixVj/jSOLnfiy9ApfC6IrboZvaMz0tJMRonpdE2iHsVux3fhTLo+7+WxOb8hWRnGIsAqBLHCgl8G6TIku4ctVPryGNTtFNq6mGs/yqtzHqFmehzfDnye5I2NBNs7Im3OuBAVxTR+3MGz199DohLkAst/UPRMHprpdM8aTKdrEvVI3cDW4UXuSOC6vttDS5aIkYNBgeJR0TwCa7/A0SUROgRiYXAK2Mr7+dXMvxJ76zEGB/KJ+cfQ2RtqEALX7ERiy3ops6g0BAyS9qrYmrsxgwtnD6bTNYl6ZDCA2tJJzpsawV0WMCQoIa+rBHQ0txdl0A997veG2YrdTsbUAlzzk7jLcQV/mvYnrpz1TZxHsqHq7HS6Wn4e3fMMbsyvJiB1fu9aRtruQWTr2d17/1fDdLom0Y+U6F1diK4uLCc6DB/q6Rk+H1QdJPVYEp7uEuJ+JzDmDNDblEhCVRg0TzSKSsfKHG48fwv/lbqDVl3nxTcWUdJ4CN0z8TvKTCpiZJjyL1pVYs5IM/lIo/e7idnWyO9757K8oJ7ecgGKGmlZY0JYrKhFU6i4tZqbk96hVde5v3MFJf/bgdHbG2l5Y0abkouWm4PidEZaSkQwna7JRxtDx3C7eaJ+PrNimgkW+NCyMiKtakwohXkcvDOdb2e9Sraq8uvOlbz5zDyMo8fOuooMLSebmu9mUvvzNDpuPifSciKC6XRNPvLIQBCv206aNkBMnA/ptEda0qjRCvPpXpLOJ5ZtY6rFxprBXF7ZO5OcTQNIvz/S8saGEAxNz+a8GbWUZnegnGynu484YY3pqokJiKREjDgHwhdADHiQHi+G13vWPbHPJoSmocTFQUoiWC2hmFpQR3h9yEEPxqAHGRiOtMzJJaBgV4axaXrofxClCE1DiY0BixUSYuk6N5PulX6+l/YOXin5dd1KUrdqyB2VkZY6ZoRmoX2hlavjm3iybz5Jdb5IS/ogioqaEP9ekvYDGBJ0HX3QM+6JKGFzusJipeeyafRe6eXLM97k+bZzaNlaSNo+g4TdHQQbjoRLyr8cak4W3RfkEvyEi/OyG7ApQRo9KeyoLCZ1u0raW50YTS1nX89pLOgCXUb/wE6dkkvP4kw8mQqW5d3cPvU5Phl3hFjFzh/d6SgvJpP+96OcbV0UoWmoqcncceMLOBU/7U0pTKusjZpSN6FpKElJdK+eimEFeZzfVQLg6NWJe6dp3LXe4XO6VgvuIoUbyndx2JfGVVn7WHTTs6g3Sd4ZKubutz5G+YODUN+E4fWGS9ZHHrWkiKZrM3nkC/dRZgliIZRECqTp+PMNPKslr3nKeLj+PMQrSaQ9tDXCiieJE3ReIomWlQmaBsEghnsA74rpHL0MVs2t5P6Mx7EISFBUnMKKRdjxywB3P3odU95sJ3isNdLyx4ySEI97cT4fj/0bV+6/hZSdKnpff6RlMfyxBTStVrh48X7y7M1cn/A8Fk5cVdGhO3iqdxHb7l48rok2YXO60u8nZ9MQazvOx94n2RIveLAQRMkg15Xu5Sfnr+Eniauxb5xN1psu9OracEn7SBPITGAo02COVcEiHCyv/jhNdZlYehWGswPMmdrEVel7+Pa0V/hHdjnrpi0md6NB3N52gkeORlr++FFU1OREykqPkan1E9QViEAoS1isqHnZ9M3PpGMRKNlDaBYdXVcI+LNZXFzPZ1MqKbB2c0yPJU8dHHG4Kro0GDCGiT9igHswsqVWQiBUdWzhQCGQWem0XKEzIAWDO1PJ39N/EtcWJhQVZWYpRz8VJD+zh92deWyoms3j/hWI44QZ0wb5RNkePpW4ja+kbuLg5zJw+wqI+0cAvacXLTMDOTSE4RkaVZgufE43GETbXUfGATt6Tx/xMU7SinLpnZHAk4uXcvXSHXxr5mvca1nJMVsKua6Ms37KZjQQjNEwHDoWoTJo+GjfkkPhFj+2ln68xUnUzyjhR+fksrDgCJel7mfOqiZ+mria5LQc0rY5MSprw3qTK7PKCSY5QJeo22rGHWsWqoqIj+OKzF0EpMqAx062zzVBak/35QLF4UBWFOHJi6GvWMU318uXz9nEUmc9MSKIjmDAsJKveXndW8SjnedxsDedn5Q+T7bmA1SC6DQFLcS2+GAoMnFQrTCfQGYiw8lWfIkq9l4d5/YG9J6+08Y41dRU3OUJfGbeZp7oW0hyjYFyuCXioQU91oaUgiON6cTWWSh4x4ulw43QjQ+c17sgkyeXLeXYgkR+k/sG9xc/w1UzvoGjcwpadzItq9Oxd0uS9/RCbcNpr9mwJtIMjwdGCrmNgQHYd4CEfZD0nJMt1y5C+w+D3856guenzOOdpoU4n+82V0+aCEaG1h16kPTdQWy7DqH39WOrhex1oaFu85JSvntFEZtX3sdNFz3M7WXL2ZI/k6md6eiuXmQwMPnOVwiarkwmOGMQQ1cpO5REsKNzXN8rLBp6UgwfiznAek8ZtNkxevomTvNJv1iE6lCL86i7OYbF8+r4XsYWVjr8I4vyWEZeIR7qK+MXr19O8n4Fi0dy7AdJBGwt2ISFAWOYzd7paHXHQomcMCI0DSUhnvaLs+mZqzO9vJmv5mzmqc6FuL41BW2PL3Rfn4JARS7tixS+kbKXGWu+QtnBvsiHFqSB1ulm6sPxWFpdBBtDy9+eyNvENRwhsbKUXY0zabzj70y3xiBnDdDmi8PW5+DJO3/Fn3qX8Pc/LCXrWAd676mdblRkFgyvl8Q/b2XD/Uv47+bVfCV1M6XfrEax2yIt7axHKoAiR4aoltDv4oPNHmxrx7lmG+VfOsA13/8GX29dxp2Zr7Pu078k4dlh3NfMRctID4veQKzkipIqfrZgDb6KXIQ6vokMIiaG3op4EhTBroEC7F1K6IE/yaglRXTdOItZjx2k6poH+M2Ul8nT+lk/5CAgP3hr69Lgt7//OOUPdJG6d4Du2YKb47uJVUKlbV26YE3LHKRn/JnzMdmQkszwitlkvBxgyed2k5nvwqkNs8rRw1OFGxgosKPEx532c1qWO7jlkg08PlBA+U8bMarqw6D+NEiJXt+AeGvvew73VOg1dWRv7OfWAzfhlwHm5TQTiJPENw7zt/55FNq6CMQQitOfhvH3dIXAe9VChlIULF5J0tqa9xYU0fLz6F2cg3VQx7m59rQLjdj7Ddx+O8mKxjWpO/lNwZUoDUdDUzqjBLW0mIHpqfSWqqjDkFQbwFnvwmg8GpVlb0GnguoMVSW4DCfKcKj05UQYQ0OkvlRLdfssrl41hxXnVvKLvJd4+8e7uavycpStxeS+3oext2ZyxEpJ6UPH2PnWfDZlLSKzsZXgSbSOmuQEOpfq2IVKTW8Gtp7J760HLp5H/WUaty7fwK1Ju7ml6Qq27y4BQ7Bwfh3LC16j3xjGkBJFCJzCSkKjDlLimhnHNas+mMzsMpw0N6VSpocvgaamJNN6Yzm51zaSbhtg610LSTwyyJFzSvn8F3QeL9jEaIKy7V9dyrQV9WRbe/nvp64jv2/XWTt6VfwBOjoS0aXEoQZQfQL79no2f3UxgViNKbUd6K6e037O+JyuomKcN4u264YpzuyifSAOQ51O0jO7UbMz6bogG/9VfQxsSSJmlwNOt7qTBEMKFBTiFB/SqoESFZ3xEELgLU6mbZlg6dIqfLqFg93pHD2WRmxDJomHgsTt78Do7A5VYETB3PKAU8FuDxBEZ5tnGpaBAHL4JMMfKdFdPTh2QMFwIVs7zuHWSxL5XfHTfG/GOp7PnMO28iIy31hM0isH0PvdE25jsKmZGM8QMYlxGN094/p8NT6eocIkVsypwSd12mrTKTw8ifXIQiDmVtB4reD6he+wOm4/v+xaxoFnysk/OExfsZXMZW40VBgp+lJHYj++JAX/sky6F+ncnLQVcLz3sa2BJGLrRxb6CQOK3U7HdWUMX+BmekIbL76wlKJtDehd3cSmz6ZlMPGfJ5+kfYTFSuC8mSStbqUwxsVvD19A3nrvya+9swHdQPr+OfISBuhuN5bttVgdduQoa3jH5XQVq4Ujq+w8uOgRPub0UxfwcIX/NpL3FNI9JwnXRT7+Pud/WV39jVF1uw0NrIqBgcGAYUcMB5GGcdq/CxtCIehUMFKHuSltKymqh+S8YZpmxvN831xerJpFUmY2CYdTsTf3I1s7wjKUDWkTqMlJoa1rFAXpHcIY9OBPEKTGetCl5M2uEjS3L7TTwCnQXT1oG3rIP5BJe18hP//sxVydvJuf5r6IL0flxtRbSKzMQvH5J34UMrK4DV1d4/+snAx6pll4OOs1tvlTSK4S2A+2TVqNq9AstJ+bwLfPf57VMXW87cvh+fWLKXn8IMagh9iY2QQNFb8MoiKwCBVVCBQErrkGWoqPK0pqmG79p8P1GsMc8meQUh1AjrfXPyojBHJ6McoVLlZkNPFq0zSKHm4IJbWlBENiHF/EehyK3Y7Iy6bx4xZ+lv8mDx89H9+GNMTWbVHRETljpIT3uSPDAmpGemjSkasPOUrbztzpCoGIjeH/XvtXFtl60aWdfM3KmkUPc/mX7+TSeXv4UtpGbAIS6kEODZ32I4N2hTg1iFfq7PPmI5vboiq0gKET92oVZbV5fLXuc/hK/MyfeoQVyQf5XMpmfnXRdoIX6fy6p4KHd59H0R/j0TbvD0vYQXE46PlYKZ4cBUOFhAaDxN2dDBYYXJ5+GK8MUH8gh2nuNoxRDu+Cbe2kPtxOY9VsvnTtOSxaVMsPc9eyfcGfOH/OHaT2D2I0t0yyZWeOa34qXNBLoWbnsrduoHjv4KTWuAqrhcTLWznPcYgN3gLu2nkFpXftQx+pO4+rdvHmM/PYc9tW5liDOBXre39be/VvsYgPx68bgzobO0txbj2EHoZhueJwUPdVK/eWPcfX3vkkpXf7CLa1v3dcqgKbdorrWQgoL6LxqkSqrv01F+77FMqTKeQ8u3vU113UoiqghRyrQx1mKCdI+9XFqJe7MF4qJmOzC72m7rQfc+ZOV0oYDvDAoRU8avPTP2RHUw22zn6a3Zf9GqdioTWo81DPEtLeaA4NRU9D57k6N2VUMWBIdvZNAT36lqwzPB6oriX/kA1UlUG7jZccs3kh5XyOXJVE8fJGrs/cwasXPoB6oeTSt79E9uNWnNuPhHpwk4Bit3Pwnhncu/Jxlto70KWkWbdxJJDKTGsb+ZpGtyHJXS+RZ5C5F1srKd1joz8jjdsK78BdYCXt1UMERxG/ihTKOdPoXDHMY7P+wna/oPieIOJA46TWhgqLxgUZ9aSoksdalpL2iu0DE330usPk/raNu96+hcOfsLNoQS3fzH6V2Tbbew633xiiJQh9ho35Np1dvjwaW1Mp6T82icrfNUAgnA5+tPBFrEJHabNjVO7/0GmGFHTrHjSf/ECHQk1Lo/3aqfgvdvPg7IeZseYrlD/QhXFkN0YUTTNXnE6U9FTw+dG7XWPrFCmhK+g/0zdyyyVbGL5EocKiM7fya6TuG92aHuMKLxheL/H3xCGVOJIkeLIsfD1zIT/LeJse3c993Rfy9zULmdK567SGqfHx5Bd1MtfRyDE9lj0HCijTP9zgE43QNBSnc2xzqqX8Zw/c4wkVWne7KPyrjndrDvfnFfDjElh2YRV3z/8rP4y5gr7iErKf0EcVaB8Lit2OKM7ni+duZKm9gw3eXB5oXE5HdTqPXP0QeZrCoAywbrCM2AMujDOp8zT00PoYLW3Y+tyk18eg9/ZGZ0JECLQpudTcFsfn5r1JQKrcsu0zlDYeRQ9Djasy4tZ1Q0E5/pKXEsPjQatsoMSbx9EtpXy6YBqDU4MIRxBpCJACxarzu8WPA14295dha7CH538tJUhJVzCOBfajLDu/ird/tJD8dV602maMfjdSEyTZvKzz5OPo8IOqolaU0js7md6rPOSnNNM+EMftT32e0jXu0EpoUeRw1ZIiOi/IQLumC7c3ntQ/5xO36xjBllE81IRAjPR0/6v5CrbWTMXWplGw7ChZb+loTZ2jCl2Ny+nKYBBtw66QHk0jJS+HdRUL6FnupHkwieb9WRSvH8VqSIoKuZksSqsjX/OyZSiPuNrJTxyoKckEZuTTVW4ndZ8HtbH9zDb4M3QMnw41dVhqID0lmZSSXLYNzKT8hna+WLKZe3wr8R4qxrZuYp2ucDjw5cTxbwl7SFIcbOwvp3NfBgkNYBcBLEKlxu/kfw4tI7O9LVRve4bIwHCoBjGMa7iqFaXo8XbUAX9o6HaquJmihrLuV+TxmSWbWBpTz0t9s0l51YHR7558xyVGl/TV3W7YU03coTgSUpMZKkkj6NRAgj9Bpa/UQuayAUBlX3c28YfDFweVwwEe2LOcokWd3JT2NgmXDvFiwjzi68pxdBv0lSpcm1xPvOqjc74TdWYxnmwI5A0zK6OTmrYMtMpYCtYPIHdVh033aPGUp+JaFGTD9D/SZdj4ZM/tZMbkkbxZEDxVqEwIDKeV7MzQtb+1ZiqZG1QSD/TT6sond99R9O7R3dsTNjlCBoMEm1qYeq+Xg7XTiT02TFlD+6gWslGsFvpmJnNubB2JisYhfwap+/2TnjiQWekcWW3nv658jv/38lXkbCogZosf3T04rhtUd/WAq4e87Sp/iLuI71z1LF+cvpn7rlhF2XrrhD75hc2KL0kjTigYGHQMxWMZELiLJCmKH59Ueb5vCfLvKejus29qddvyVNzFBo7OWPL7sjDcAxiDJ54KqyYlMDwjj0s/u4XbknfwtLuCNXvmUvaX04+0JprTJZsgNEHIGBjA0tgUmiahqNiWzqRrkY1ZVjv9xhBdzUmUV/YTrnSy4fFS/DvJ3WmXcGfhG9yZuonvXvUmG4ay2eIuJdPq5vbERgwkmz69nRxbLzPtLbzhruDlNUsoeqUfcWBvdK6fIgTdMzSWVBxgiuYkF8kLqx7gxtTPIpVcktcOhKbynmAikOJwMJTu4I6il+jQh4mvsZC8rZVgwxEy9zKm5OzEzkgzdPSuLpIeC8UuRytEJMSj3dLBXFsn+4advHB0Fqnb6iY98K70ukmuSiLlmkF23XAvD10yi4c2L6fiF+0Em5rHn2k1dIp/WsUvpq7i17Of5ver/sDPl96M+k7NhK3opbt6Sdzl5OfdS/lqyhaeLH4Jb1GAVDWGbl1wW9Nq9vx9GgWPVYbtxp1IvFmSL65azyWx1dx71cVse2kmhY80fCC5A6DExNB3USmptx/hZxn72TQUx33rVjPtURd6mIa3cniYHb353JS4HadlGJdzbKvsqGVFNC938udLHwQUvtm6guQ9KrL60OQIPhGGjnhrL3FfmMKDZdfTU2HFv2SAm8p38H9S3qLMYmBg4dnBVFqHEnhp83yyNkvi3zhIXt/bSEZVvhsRtOwsjLkDfDFrIzv8kmFU5lt13ln4B16fmcrXlt1I4d90HLUdGF3dH0jiBxeU0bJc4+qYHso3fIWSze4zXhkx4nukaYX5dKzM5q/lvyRLdXLjgWuRL6RgDE7+rJVgWwcpa4e4r/MGvna1wmXz9vH0pb/h6UWLWPvKYrK3BHFWHhtXxtsYHMTXEUONP4eLYw7QMc9B7j47+gQ5XRkYxmhuZce35rP0+vnMLGmhJLaTHd35uNdmkb7bS+GhQ+iDgxPyfeFm6oMNPN51CU+uWMDDs/7MFz67iW+efx3tu5aQvtsgvrqHQHosDZfZmbO0jnumvMDRINz+x29SvH4Qo/5I+MTqOtU1eRybEstlGVXcsyiH5EdH96diwUwOfsbJJ5a+zRxrkKPBYd5+Zg65W3sikoTSW1qxd7nI2WVHPBfD285ZvDrtAnqmqQxXeCn8LVhcHsrdR5EDg+jhKo0cB+6FeczJrmOrp4RHn7uIlCpJwm1H+fqU11jl6GHtx+7j8MoUXnDNpaY3B1dfLEKRKIpkQe5hFtj7KHvjc5T9aggOHT3jh8sZOV3F6YSiKXQtTiL2WBDn4R7o7B7zfGo1KYn+uZkELu+j0BLLLv8wLbXplO50j7rmbVwYOnpvL45t9RTqU9l4dB5vLijm86VvcemlO1g/rQxjXwF5r6ehbK8+4yGqtBjEKT4swiAQB4xzauuHPt/vx76rgQKlmPaMQlochdjckuxdnciWtrNv48L3EWzvIPuNJHpdidzQ/GUuXrifT+btpDYlk73zcqntSiQm1scnC3ayKr4SrxRcvvU28jd6UWubw9bLhdBW8bENGl3BeBY5DzG9vAKjohT94OEThqsUpxMlMx3X0kw6lgf51Ly3uS5hJy16kMve+jKFb3kQR9vCpv/9yGAwdL17PNAdWiAo3pVO7JE0hvbFoO2uQh8aOqvqblvPE1wQ083rneXkveHDWtdGZ2whXyz/PJaiAeZmt3BpSiWXJFdycVI1bsNBrTeTXa4pvNNUgNEcw5RNQahtxBhHp+mMnK5wOhicGo//sn5cHbHEH8wg+WAyzgPtoZ0I3IOnXSBFjY/HP7eI9iWCh2c+Q0Dq3Nu2iqRqBVE7uaU9x6P39WN5fRcFh/Ppq8/kwesu4Jdz/8YNc7bxZP5iXrXPp0DMwHKkE8PVM6baYbW0mPj0QYqtoQTdZK2jrbt6sL7ag/X9703OV4Udo+ogSY0xJO/J5U3XHI5dkMh5KYdYVlhHfLGPZHUQn7TQMJzO/V2zyHjGgbavJuy9L6nrJB8Mssebz9ykVq7P3MGvLr6e3AEvst8dylEoCsJqQTidDOen0jPdQfDSPh6b9RcKtEGag04eaFtJ1tNW1KoDUdWD1Ds6oaMT+y7OrlCVEKhxcSxYVEdAqhw6nEn5zhqCHg8pT/SSlp+LpzSFPbMq2DqtkCmZPRTFuUi0ePlH21R6DiWTvF+QursfY2/NuG0/s/CClARtCouzm7hvwUa8lwW4teEa6l8rJqlOJ2F3B0aXCzk09OFkmFAQqop/fgkdX/Jx98ynudAe4GhwiAOPTSNjQ8d7xeThJtjYROyRo8Svc/K1H9/Mv1+0ie9nbOJnN2/mixd+jOonKsjckoCorg/ZdZqnvLDZqL0tlZ9Oe5rz7EHqAgLNS9imc36UeK8++gdglBSxdsYKXBUqxjkDOGwB+jrjiK21kLOxH+eubZFxCoaOY/0+/vLJ+Uxd0MF1sUdJ/8of+I7/FhIbAmiDAaSq4Euz0luiYlnaw0+mP8VlTh8BqfOKN53vVF5N8mMxOF7YfnY5tihGcTgIzCriOzkPcWv1p0neqb23Mpr0+9HrDmOvO0zu2tD5WmYGbUlZtFo1UmoOkxwITXiYqPY4I6eru3qIf34Prf9IYtW5X6H1ygC3zH6bx25/HkNKXvPmsNZ1Dm8fmkXCdju2XgMhwdAEQ2mCxFVt3Fv6O6ZadOxCo3LY4N/v/iZZa+rRu7snyLQzZKSWsuTbe9jy5Hz+umwFOR8/wnOlL+D79iv8pmc2j1QuJf0lGwk1fdB47ENTfRW7HcoKOfSpRLZc80vSVScuY4i1g7OY8mJX+KYGf0TRDzXiPNxEzFoVoYaGDhkjU1THUxI3EUi/n7If9fPf/3Ydjde+yfdTK1ny3XtoCcKAYcUuguRrOooQ2IWG1wjw7GAm//nGDeSvleTvPUaw7WBEbfioIRx2essdJI4UTh+/SPnxBNs74N3S0UkIn5xxIk36/QQ7uojfbBB7JJ11xRfyRNkKYhd2c25WA5en7OO6tJ00zE1nQA/N1FCFQYI6xFJnPTOsgm1+Bw+1LWfn5nJKXm4JFdxHSYxI+v0oBxrJdaXiq8xi5so7yF/UwqUZ1dyz8Gn2zCig0p1NZWshRmMMSQfBOmDQM01lKC9A5pQeflz0FOmqkyE5zE86LmT9iwsoaNoblauRnVVICVJHGjoyCneUlc2tFKyx8krT+Ty1eh7/95x1lNvaSFD8qEJSE3Dwcv9sXm6ajrc2keQqKK/sR7R0hPIi0Tjp5Czn3bDeeZmHWZufSspp/2Dy/ND4qhcM/b04T+KhBBKqs+g6lsKr+Sm8WDCLpKRBYqwBpsT1kmXvx6YEGdDt3Oe+iIb+VI61JhNTZyX/raGo3BrG8HgwGj1oTS0UuSvoaM3jgYos8qd2siz9MJemVrEqtYaq4hy2VBTRP2Rj0ZQjLE04zAJHI7OtGtWBYR7qupDX3ppN8eue6KxfNJlQDJ8PUdtAmisZdbiAH7Zfh0j2Y7GFHrZ+jxXbURvxjZKM+iG0g0cnfKaiyYlZENvImrR5oQlZEXq4TVjJmN7XD339pFRBCqDlZCMT49BjYqkvz2RvtsCwgAiCs0OSXDVIxbFWjN6+6HdEho7cUUn6DsjOysRfls2z52djTB/k8qlVrEg4wC0pW4hTAlgE6BJ8UmGzz87/tK9k/4vTmPrmILwz+dOaTaIDGRgm2NZO/F/aSXolAZEQjxzZ+l14Xegdne+NeMx+7SRjSNRh8BgKmVo/SkwQoQhkhILmk1anGzzWCiPTmRO3Q+KJzpmsL59Egm3tqG3tTNkU+v1gViZVedNxF8fQPUcQTAoihhTsHSoZO4dx7G4it3e7GVL4F+bdDolJZDC8XlL29PGsey5buouxHXRE9H6M+OSIs51gRxeip5fEao2k9XaEpoVqjINBpMcbmgQRJXFqE5N/RaTfDzWH2fLZBSgeP4U9hyPa4TOd7ngxdKRfDzXsWTwJwcTko4wMDKNUH8YIBMOzGPwpMJ2uiYnJvwTRkjuKog3ITExMTD76iFOtcSCE6AJOvz9xZMmXUqad7KBpQ9gwbYgOTBuig5PacEqna2JiYmIysZjhBRMTE5MwYjpdExMTkzBiOl0TExOTMGI6XRMTE5MwYjpdExMTkzDy/wEb4UG3ofZR7gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 28 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_pic(pic: np.array, pic_label: int, axes: plt.Axes) -> None:\n",
    "    axes.imshow(pic)\n",
    "    axes.set_title(pic_label)\n",
    "    axes.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "\n",
    "ncols = 7\n",
    "nrows = math.ceil(len(unique_classes) / ncols)\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "for i in range(len(unique_classes)):\n",
    "    pic = np.array(classes_sample[i]).reshape(32, 32)\n",
    "    show_pic(pic, classes_sample_label[i], axes.flatten()[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also vital to know the interval of pixels' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixels' interval : [0:255]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pixels' interval : [{train_df.values.min()}:{train_df.values.max()}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity I will consider only the first 16 classes, thus I wil remove the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_classes(df: pd.DataFrame, labels: pd.DataFrame):\n",
    "    indexes_to_drop = labels.index[labels[0] > 16]\n",
    "    df.drop(indexes_to_drop, inplace=True)\n",
    "    labels.drop(indexes_to_drop, inplace=True)\n",
    "\n",
    "trim_classes(train_df, train_labels_df)\n",
    "trim_classes(test_df, test_labels_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot for the count of training and testing images within the 16 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "width = 0.4\n",
    "unique_classes = train_labels_df[0].unique()\n",
    "x = np.arange(len(unique_classes))\n",
    "train_count_per_class = train_labels_df[0].value_counts().sort_index()\n",
    "test_count_per_class = test_labels_df[0].value_counts().sort_index()\n",
    "\n",
    "plt.bar(x - width/2, train_count_per_class, width, label='train')\n",
    "plt.bar(x + width/2, test_count_per_class, width, label='test')\n",
    "plt.xticks(x);\n",
    "plt.title('Data count per class');\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now scale and normalize the pixel values.  \n",
    "This will bring the pixel values in the range of 0 to 1.\n",
    "\n",
    "Inputs with large values can slow down the learning process or even break it.  \n",
    "Giving unnormalized inputs to activation functions can get us stuck in a flat region and cease learning.  \n",
    "Sometimes there can be numerical issues (such as division by zero) as well.  \n",
    "Normalization also helps the gradient descent process for back propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df / 255\n",
    "test_df = test_df / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding for the 16 first labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7676</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7679</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7680 rows  16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9    10   11   12   13  \\\n",
       "0     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "7675  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7676  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7677  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7678  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7679  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       14   15  \n",
       "0     0.0  0.0  \n",
       "1     0.0  0.0  \n",
       "2     0.0  0.0  \n",
       "3     0.0  0.0  \n",
       "4     0.0  0.0  \n",
       "...   ...  ...  \n",
       "7675  0.0  1.0  \n",
       "7676  0.0  1.0  \n",
       "7677  0.0  1.0  \n",
       "7678  0.0  1.0  \n",
       "7679  0.0  1.0  \n",
       "\n",
       "[7680 rows x 16 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = np.zeros((train_labels_df[0].size, train_labels_df[0].nunique()))\n",
    "onehot[np.arange(train_labels_df[0].size), train_labels_df[0].values - 1] = 1\n",
    "pd.DataFrame(onehot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done because the labels are not ordinal and a higher number does not imply anything.  \n",
    "Now the last layer of the neural network can have 16 neurons corresponding to the 16 classes, and whichever gets a higher number will be chosen as the predicted class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 n_classes,\n",
    "                 batch_size,\n",
    "                 shuffle):\n",
    "        assert data.shape[0] == labels.shape[0]\n",
    "        \n",
    "        self._n_classes = n_classes\n",
    "        self._batch_size = batch_size\n",
    "        self._shuffle = shuffle\n",
    "        self._data = np.matrix(data)\n",
    "        self._onehot_labels = self._onehot(labels[0], self._n_classes)\n",
    "\n",
    "    def _onehot(self, labels, n_classes):\n",
    "        onehot = np.zeros((labels.size, labels.nunique()))\n",
    "        onehot[np.arange(labels.size), labels.values - 1] = 1\n",
    "        return onehot\n",
    "\n",
    "    def _shuffle_dataset(self):\n",
    "        perm = np.random.permutation((self._data.shape[0]))\n",
    "        self._data = self._data[perm]\n",
    "        self._onehot_labels = self._onehot_labels[perm]\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self._shuffle:\n",
    "            self._shuffle_dataset()\n",
    "\n",
    "        if self._batch_size == None:\n",
    "            yield (self._data, self._onehot_labels)\n",
    "            return\n",
    "\n",
    "        for idx in range(0, self._data.shape[0], self._batch_size):\n",
    "            yield (self._data[idx:idx+self._batch_size],\n",
    "                   self._onehot_labels[idx:idx+self._batch_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: The Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identical:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        relu_value = np.where(matrix < 0, 0, matrix)\n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        relu_derivative = np.where(matrix < 0, 0, 1)\n",
    "        return relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyReLU:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        self.negative_slope = 0.01\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        leaky_relu_func = np.vectorize(lambda x : self.negative_slope * x if x < 0 else x)\n",
    "        leaky_relu_value = leaky_relu_func(matrix)\n",
    "        return leaky_relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        leaky_relu_derivative_func = np.vectorize(lambda x : self.negative_slope if x < 0 else 1)\n",
    "        leaky_relu_derivative = leaky_relu_derivative_func(matrix)\n",
    "        return leaky_relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        sigmoid_func = np.vectorize(lambda x: 1/(1+np.exp(-x)))\n",
    "        sigmoid_value = sigmoid_func(matrix)\n",
    "        return sigmoid_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        sigmoid_derivative_func = np.vectorize(\n",
    "            lambda x : np.exp(-x)/np.power((np.exp(-x) + 1), 2)\n",
    "        )\n",
    "        sigmoid_derivative = sigmoid_derivative_func(matrix)\n",
    "        return sigmoid_derivative\n",
    "\n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMax:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        def softmax(row):\n",
    "            new = row - np.max(row)\n",
    "            return np.exp(new)/np.sum(np.exp(new))            \n",
    "        softmax_value = np.apply_along_axis(softmax, 1, temp)\n",
    "        return softmax_value\n",
    "\n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        tanh_value = np.tanh(matrix)\n",
    "        return tanh_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        tanh_derivative_func = np.vectorize(\n",
    "            lambda x : 4 / np.power(np.exp(x) + np.exp(-x), 2)\n",
    "        )\n",
    "        tanh_derivative = tanh_derivative_func(matrix)\n",
    "        return tanh_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:  # (with softmax)\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "        assert np.shape(true_val) == np.shape(expected_val)\n",
    "        mat_true_val = np.matrix(true_val)\n",
    "        mat_expected_val = np.matrix(expected_val)\n",
    "        mat_true_val = SoftMax()(mat_true_val)\n",
    "        log = np.log(mat_true_val)\n",
    "        cross_entropy_value = -1 * np.sum(np.multiply(expected_val, log), axis=1)\n",
    "        return cross_entropy_value\n",
    "\n",
    "    def derivative(self, true_val, expected_val):\n",
    "        assert np.shape(true_val) == np.shape(expected_val)\n",
    "        mat_true = np.matrix(true_val)\n",
    "        mat_true = SoftMax()(mat_true)\n",
    "        mat_expected = np.matrix(expected_val)\n",
    "        cross_entropy_derivative = mat_true - mat_expected\n",
    "        return cross_entropy_derivative\n",
    "\n",
    "    def __call__(self, true_val, expected_val):\n",
    "        return self.__val(true_val, expected_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
    "\n",
    "    def __init__(self, input_size, output_size, activation=Identical(), initial_weight='uniform',\n",
    "                 **initializing_parameters):\n",
    "\n",
    "        assert type(initial_weight) == str, 'Undefined activation function!'\n",
    "\n",
    "        self.__weight_initializer_dict = {\n",
    "            'uniform': self.__uniform_weight, 'normal': self.__normal_weight}\n",
    "\n",
    "        assert initial_weight in self.__weight_initializer_dict, 'Undefined weight initialization function!'\n",
    "\n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(\n",
    "            input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(\n",
    "            1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "\n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "\n",
    "    def forward(self, layer_input):\n",
    "        assert np.ndim(layer_input) == 2\n",
    "        assert np.size(self.__weight, 0) == np.size(layer_input, 1)\n",
    "\n",
    "        self.__last_input = np.matrix(layer_input)\n",
    "        self.__last_activation_input = (self.__last_input * self.__weight) + self.__bias\n",
    "        self.__last_activation_output = self.__activation(\n",
    "            self.__last_activation_input\n",
    "        )\n",
    "        self.__last_activation_derivative = self.__activation.derivative(\n",
    "            self.__last_activation_input\n",
    "        )\n",
    "\n",
    "        return self.__last_activation_output\n",
    "\n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "        assert np.ndim(backprop_tensor) == 2\n",
    "        assert np.size(backprop_tensor, 0) == np.size(\n",
    "            self.__last_activation_derivative, 0\n",
    "        )\n",
    "        assert np.size(backprop_tensor, 1) == self.__n_neurons\n",
    "\n",
    "        ones = np.matrix(np.ones((np.size(backprop_tensor,axis=0), 1)))\n",
    "\n",
    "        dy = np.multiply(backprop_tensor, self.__last_activation_derivative)\n",
    "        db = np.matmul(np.transpose(ones), dy)\n",
    "        dw = np.matmul(np.transpose(self.__last_input), dy)\n",
    "        \n",
    "        backprop_tensor = np.matmul(dy, np.transpose(self.__weight))\n",
    "\n",
    "        self.__weight -= lr * dw\n",
    "        self.__bias -= lr * db\n",
    "        \n",
    "        return backprop_tensor\n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys():\n",
    "            low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys():\n",
    "            high = initializing_parameters['high']\n",
    "        weights = np.matrix(np.random.uniform(low, high, size=(dim1, dim2)))\n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys():\n",
    "            mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys():\n",
    "            var = initializing_parameters['var']\n",
    "        weights = np.matrix(np.random.normal(mean, np.sqrt(var), size=(dim1, dim2)))\n",
    "        return weights\n",
    "\n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "\n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "\n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "\n",
    "    @property\n",
    "    def activation(self): return self.__activation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "\n",
    "        self.__layers_list = []\n",
    "\n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "    def add_layer(self, n_neurons, activation=ReLU(), initial_weight='uniform', **initializing_parameters):\n",
    "        assert type(\n",
    "            n_neurons) == int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons > 0, \"Invalid number of neurons for the layer!\"\n",
    "\n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list) == 0 \\\n",
    "            else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(\n",
    "            n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters\n",
    "        )\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons\n",
    "\n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        assert self.__layers_list, \"Incomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "\n",
    "    def forward(self, network_input):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "\n",
    "        layer_input = network_input\n",
    "        for l in self.__layers_list:\n",
    "            layer_input = l.forward(layer_input)\n",
    "        network_output = layer_input\n",
    "\n",
    "        return network_output\n",
    "\n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(\n",
    "            self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\": [], \"train_loss\": [],\n",
    "               \"test_accuracy\": [], \"test_loss\": []}\n",
    "\n",
    "        for epoch in range(1, epochs+1):\n",
    "\n",
    "            if print_results:\n",
    "                print('Epoch {}:'.format(epoch))\n",
    "\n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(\n",
    "                    average_accuracy, average_loss))\n",
    "\n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(\n",
    "                        average_accuracy, average_loss))\n",
    "\n",
    "        return log\n",
    "\n",
    "    def __train(self, trainloader):\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(\n",
    "                x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    def __test(self, testloader):\n",
    "        batch_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            batch_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(batch_accuracies), np.mean(batch_losses)\n",
    "\n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        network_output = self.forward(x_batch)\n",
    "        batch_accuracy = self.__compute_accuracy(network_output, y_batch)\n",
    "        batch_average_loss = np.mean(self.__loss(network_output, y_batch))\n",
    "        self.__update_weights(network_output, y_batch)\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "\n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        network_output = self.forward(x_batch)\n",
    "        batch_accuracy = self.__compute_accuracy(network_output, y_batch)\n",
    "        batch_average_loss = np.mean(self.__loss(network_output, y_batch))\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "\n",
    "    def __get_labels(self, outputs):\n",
    "        labels = outputs.argmax(axis=1)\n",
    "        return labels\n",
    "\n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "        predicted_labels = self.__get_labels(np.matrix(output))\n",
    "        expected_labels = self.__get_labels(np.matrix(expected_output))\n",
    "        accuracy = np.count_nonzero(predicted_labels == expected_labels) * 100 / \\\n",
    "            np.size(expected_labels, axis=0)\n",
    "        return accuracy\n",
    "\n",
    "    def __update_weights(self, output, y_train):\n",
    "        backprop_tensor = self.__loss.derivative(output, y_train)\n",
    "        for layer in reversed(self.__layers_list):\n",
    "            backprop_tensor = layer.update_weights(backprop_tensor, self.__lr)\n",
    "        return\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Classifying Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_network(\n",
    "    activation_function: ReLU | LeakyReLU | Sigmoid | Tanh,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    batch_size: int) -> None:\n",
    "\n",
    "    INPUT_SHAPE = 32 * 32\n",
    "    N_CLASSES = 16\n",
    "    train_loader = Dataloader(train_df, train_labels_df, N_CLASSES, batch_size, True)\n",
    "    test_loader = Dataloader(test_df, test_labels_df, N_CLASSES, batch_size, True)\n",
    "\n",
    "    network = FeedForwardNN(INPUT_SHAPE)\n",
    "    network.add_layer(40, activation_function, 'uniform')\n",
    "    network.add_layer(20, activation_function, 'uniform')\n",
    "    network.add_layer(16, Identical(), 'uniform')\n",
    "    network.set_training_param(loss=CrossEntropy(), lr=lr)\n",
    "    log = network.fit(epochs, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 9.973958333333334\tAverage Loss: 2.651851510235027\n",
      "\tTest: Average Accuracy: 12.65625\tAverage Loss: 2.5172908448686018\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 19.53125\tAverage Loss: 2.264071447787922\n",
      "\tTest: Average Accuracy: 25.677083333333332\tAverage Loss: 2.030436573505536\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 28.971354166666668\tAverage Loss: 1.9276563613559645\n",
      "\tTest: Average Accuracy: 32.083333333333336\tAverage Loss: 1.8066531481798158\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 35.885416666666664\tAverage Loss: 1.70308563983712\n",
      "\tTest: Average Accuracy: 37.708333333333336\tAverage Loss: 1.6430705032652995\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 45.026041666666664\tAverage Loss: 1.4632958493425872\n",
      "\tTest: Average Accuracy: 44.270833333333336\tAverage Loss: 1.435243455440687\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 51.4453125\tAverage Loss: 1.274648405555079\n",
      "\tTest: Average Accuracy: 53.958333333333336\tAverage Loss: 1.2192989106794156\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 55.729166666666664\tAverage Loss: 1.1379505238884478\n",
      "\tTest: Average Accuracy: 55.677083333333336\tAverage Loss: 1.1445908021539601\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 59.661458333333336\tAverage Loss: 1.018680359732854\n",
      "\tTest: Average Accuracy: 53.28125\tAverage Loss: 1.1559068175865277\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 61.861979166666664\tAverage Loss: 0.9471357148817512\n",
      "\tTest: Average Accuracy: 59.947916666666664\tAverage Loss: 1.0263535922803426\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 63.697916666666664\tAverage Loss: 0.8863639662166274\n",
      "\tTest: Average Accuracy: 62.604166666666664\tAverage Loss: 0.993646905335651\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "run_network(ReLU(), EPOCHS, 0.005, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: The effect of having weights set to zero\n",
    "If all weights were set to zero, the derivative of each neuron would be the same and thus the back propagation method would have failed. This is the same is getting stuck in a local maxima in the search space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: The effect of the leaning rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Low learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 6.6796875\tAverage Loss: 2.7346042241147615\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.7224456208079024\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 6.028645833333333\tAverage Loss: 2.716952242578689\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.706099685458523\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 6.966145833333333\tAverage Loss: 2.698597610843686\n",
      "\tTest: Average Accuracy: 6.927083333333333\tAverage Loss: 2.6903570968855344\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 7.369791666666667\tAverage Loss: 2.682076301251977\n",
      "\tTest: Average Accuracy: 8.489583333333334\tAverage Loss: 2.6700120715297166\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 8.9453125\tAverage Loss: 2.66414506306456\n",
      "\tTest: Average Accuracy: 9.114583333333334\tAverage Loss: 2.6500483114825846\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 10.598958333333334\tAverage Loss: 2.6440420885784714\n",
      "\tTest: Average Accuracy: 11.197916666666666\tAverage Loss: 2.630149074076287\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 11.002604166666666\tAverage Loss: 2.622451293949354\n",
      "\tTest: Average Accuracy: 12.34375\tAverage Loss: 2.603686743993419\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 12.734375\tAverage Loss: 2.5971086377827506\n",
      "\tTest: Average Accuracy: 12.708333333333334\tAverage Loss: 2.5781168381955912\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 13.489583333333334\tAverage Loss: 2.571010309850492\n",
      "\tTest: Average Accuracy: 13.385416666666666\tAverage Loss: 2.548766635313029\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 12.734375\tAverage Loss: 2.545325320125415\n",
      "\tTest: Average Accuracy: 13.541666666666666\tAverage Loss: 2.5238245969519864\n"
     ]
    }
   ],
   "source": [
    "run_network(ReLU(), EPOCHS, 0.0005, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 6.028645833333333\tAverage Loss: 3.675253276262154\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.1474099696778546\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 5.9765625\tAverage Loss: 3.150666369622319\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.9087563428865506\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 6.1328125\tAverage Loss: 3.1222263227215397\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.119418899479062\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 5.885416666666667\tAverage Loss: 3.153979532045519\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.934578890945155\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 5.9375\tAverage Loss: 3.1530376464321686\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.660271004701134\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 5.950520833333333\tAverage Loss: 3.128254463817231\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.0298914133872867\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 5.78125\tAverage Loss: 3.12266410704781\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.0018172979556863\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 6.002604166666667\tAverage Loss: 3.1439923018704525\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.1489728138680877\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 6.796875\tAverage Loss: 3.1136616925918217\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.9827843130839127\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 6.393229166666667\tAverage Loss: 3.1254917395462534\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 3.0804174521570546\n"
     ]
    }
   ],
   "source": [
    "run_network(ReLU(), EPOCHS, 0.5, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be sen from the results, the training process takes way longer than usual as it updates the neurons with much smaller steps. Also the model with high learning rate barely observe a change in its accuracy as it can't converge properly and miss the maxima due to its high learning rate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: The effects of different activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 6.263020833333333\tAverage Loss: 2.784274686172886\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.7804041809874565\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 6.484375\tAverage Loss: 2.781856398535658\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.783611094133973\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 6.5625\tAverage Loss: 2.778955354995986\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.7754473091108673\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 6.223958333333333\tAverage Loss: 2.774671123528523\n",
      "\tTest: Average Accuracy: 6.25\tAverage Loss: 2.7678054173192113\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 7.8515625\tAverage Loss: 2.765220447707628\n",
      "\tTest: Average Accuracy: 9.6875\tAverage Loss: 2.757223503787394\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 9.0234375\tAverage Loss: 2.751429202989877\n",
      "\tTest: Average Accuracy: 8.854166666666666\tAverage Loss: 2.740420226641902\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 9.895833333333334\tAverage Loss: 2.733341928640517\n",
      "\tTest: Average Accuracy: 13.177083333333334\tAverage Loss: 2.716518257100416\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 10.3515625\tAverage Loss: 2.710001236779894\n",
      "\tTest: Average Accuracy: 11.354166666666666\tAverage Loss: 2.6919328413069366\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 10.598958333333334\tAverage Loss: 2.6752975334435543\n",
      "\tTest: Average Accuracy: 13.229166666666666\tAverage Loss: 2.6457376276769202\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 11.0546875\tAverage Loss: 2.623459057786138\n",
      "\tTest: Average Accuracy: 11.822916666666666\tAverage Loss: 2.5876695897721604\n"
     ]
    }
   ],
   "source": [
    "run_network(Sigmoid(), EPOCHS, 0.005, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 7.6171875\tAverage Loss: 2.734107232656607\n",
      "\tTest: Average Accuracy: 12.239583333333334\tAverage Loss: 2.5972573113090633\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 12.721354166666666\tAverage Loss: 2.44241275234304\n",
      "\tTest: Average Accuracy: 14.114583333333334\tAverage Loss: 2.340789229598266\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 19.010416666666668\tAverage Loss: 2.2084578174277625\n",
      "\tTest: Average Accuracy: 28.229166666666668\tAverage Loss: 1.9488411838067417\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 29.231770833333332\tAverage Loss: 1.8680059578963584\n",
      "\tTest: Average Accuracy: 32.8125\tAverage Loss: 1.760528677143237\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 37.473958333333336\tAverage Loss: 1.6529229167700057\n",
      "\tTest: Average Accuracy: 40.677083333333336\tAverage Loss: 1.5185636779084668\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 45.611979166666664\tAverage Loss: 1.4093784852119895\n",
      "\tTest: Average Accuracy: 48.645833333333336\tAverage Loss: 1.37460247304571\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 51.067708333333336\tAverage Loss: 1.2371928984599243\n",
      "\tTest: Average Accuracy: 50.989583333333336\tAverage Loss: 1.2951220933074459\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 56.666666666666664\tAverage Loss: 1.1020042380830295\n",
      "\tTest: Average Accuracy: 55.625\tAverage Loss: 1.1548490227031558\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 61.2109375\tAverage Loss: 0.9821724835659396\n",
      "\tTest: Average Accuracy: 60.729166666666664\tAverage Loss: 1.0536969793196562\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 63.802083333333336\tAverage Loss: 0.9011540991664747\n",
      "\tTest: Average Accuracy: 62.291666666666664\tAverage Loss: 0.9933243884939176\n"
     ]
    }
   ],
   "source": [
    "run_network(Tanh(), EPOCHS, 0.005, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\tTrain: Average Accuracy: 9.427083333333334\tAverage Loss: 2.652358629230238\n",
      "\tTest: Average Accuracy: 11.875\tAverage Loss: 2.52819965411359\n",
      "Epoch 2:\n",
      "\tTrain: Average Accuracy: 13.424479166666666\tAverage Loss: 2.427623208269361\n",
      "\tTest: Average Accuracy: 20.833333333333332\tAverage Loss: 2.1448251277645096\n",
      "Epoch 3:\n",
      "\tTrain: Average Accuracy: 24.895833333333332\tAverage Loss: 2.0321930916050754\n",
      "\tTest: Average Accuracy: 29.6875\tAverage Loss: 1.8533905552884566\n",
      "Epoch 4:\n",
      "\tTrain: Average Accuracy: 32.174479166666664\tAverage Loss: 1.7860344638009438\n",
      "\tTest: Average Accuracy: 36.197916666666664\tAverage Loss: 1.7005923861819034\n",
      "Epoch 5:\n",
      "\tTrain: Average Accuracy: 39.518229166666664\tAverage Loss: 1.5748181869454165\n",
      "\tTest: Average Accuracy: 41.510416666666664\tAverage Loss: 1.4761820662530434\n",
      "Epoch 6:\n",
      "\tTrain: Average Accuracy: 45.78125\tAverage Loss: 1.387683867297523\n",
      "\tTest: Average Accuracy: 48.229166666666664\tAverage Loss: 1.3892888613621701\n",
      "Epoch 7:\n",
      "\tTrain: Average Accuracy: 53.111979166666664\tAverage Loss: 1.2185028877627766\n",
      "\tTest: Average Accuracy: 52.5\tAverage Loss: 1.2039887899288861\n",
      "Epoch 8:\n",
      "\tTrain: Average Accuracy: 56.497395833333336\tAverage Loss: 1.0803266104261355\n",
      "\tTest: Average Accuracy: 58.645833333333336\tAverage Loss: 1.119352506701424\n",
      "Epoch 9:\n",
      "\tTrain: Average Accuracy: 60.638020833333336\tAverage Loss: 0.9823887984518652\n",
      "\tTest: Average Accuracy: 60.104166666666664\tAverage Loss: 1.0630044134667207\n",
      "Epoch 10:\n",
      "\tTrain: Average Accuracy: 63.502604166666664\tAverage Loss: 0.8987554748551488\n",
      "\tTest: Average Accuracy: 58.90625\tAverage Loss: 1.0673373849556727\n"
     ]
    }
   ],
   "source": [
    "run_network(LeakyReLU(), EPOCHS, 0.005, BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Using Tensorflow and Keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Preparing Data and Designing the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train new shape: (50000, 3072)\n",
      "x_test new shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "print(f\"x_train new shape: {x_train.shape}\")\n",
    "print(f\"x_test new shape: {x_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train / 255\n",
    "x_test_norm = x_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(np.unique(y_train))\n",
    "one_hot_y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "one_hot_y_test = tf.keras.utils.to_categorical(y_test, n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50, input_dim=32*32*3, activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dense(30, activation=keras.activations.relu),\n",
    "        keras.layers.Dense(n_classes, activation=keras.activations.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=keras.losses.categorical_crossentropy, metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9485 - accuracy: 0.2954 - val_loss: 1.8437 - val_accuracy: 0.3330\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7638 - accuracy: 0.3708 - val_loss: 1.7216 - val_accuracy: 0.3855\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6944 - accuracy: 0.3969 - val_loss: 1.6598 - val_accuracy: 0.4030\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6482 - accuracy: 0.4133 - val_loss: 1.6356 - val_accuracy: 0.4128\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6077 - accuracy: 0.4287 - val_loss: 1.6376 - val_accuracy: 0.4147\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5790 - accuracy: 0.4371 - val_loss: 1.5681 - val_accuracy: 0.4451\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5549 - accuracy: 0.4478 - val_loss: 1.6095 - val_accuracy: 0.4328\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5322 - accuracy: 0.4558 - val_loss: 1.5680 - val_accuracy: 0.4413\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5126 - accuracy: 0.4613 - val_loss: 1.6143 - val_accuracy: 0.4271\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4980 - accuracy: 0.4673 - val_loss: 1.5968 - val_accuracy: 0.4359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f58ef4fd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_norm, one_hot_y_train, validation_data=(x_test_norm, one_hot_y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.47      0.39      5000\n",
      "           1       0.41      0.70      0.52      5000\n",
      "           2       0.46      0.11      0.18      5000\n",
      "           3       0.34      0.12      0.18      5000\n",
      "           4       0.51      0.24      0.33      5000\n",
      "           5       0.29      0.44      0.35      5000\n",
      "           6       0.76      0.14      0.23      5000\n",
      "           7       0.60      0.42      0.49      5000\n",
      "           8       0.33      0.85      0.48      5000\n",
      "           9       0.48      0.41      0.44      5000\n",
      "\n",
      "    accuracy                           0.39     50000\n",
      "   macro avg       0.45      0.39      0.36     50000\n",
      "weighted avg       0.45      0.39      0.36     50000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(x_train)\n",
    "y_train_pred = np.argmax(y_train_pred, axis=1)\n",
    "print(classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.48      0.40      1000\n",
      "           1       0.40      0.68      0.51      1000\n",
      "           2       0.44      0.11      0.18      1000\n",
      "           3       0.35      0.13      0.19      1000\n",
      "           4       0.47      0.22      0.30      1000\n",
      "           5       0.27      0.42      0.33      1000\n",
      "           6       0.68      0.14      0.23      1000\n",
      "           7       0.57      0.38      0.46      1000\n",
      "           8       0.32      0.83      0.46      1000\n",
      "           9       0.47      0.37      0.42      1000\n",
      "\n",
      "    accuracy                           0.38     10000\n",
      "   macro avg       0.43      0.38      0.35     10000\n",
      "weighted avg       0.43      0.38      0.35     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Checking on different changes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum and its effects\n",
    "momentum is a method used to speed up training of neural networks. It helps to avoid getting stuck in local minima by building up momentum as the optimizer traverses the loss surface. The momentum term allows the optimizer to continue moving in the same direction even if the gradient changes sign, which can help to prevent the optimizer from oscillating or getting stuck in a suboptimal solution. It is often used in conjunction with other optimization algorithms such as stochastic gradient descent (SGD) and is typically set to a value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9047 - accuracy: 0.3133 - val_loss: 1.7599 - val_accuracy: 0.3735\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7244 - accuracy: 0.3816 - val_loss: 1.7558 - val_accuracy: 0.3639\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6456 - accuracy: 0.4126 - val_loss: 1.6362 - val_accuracy: 0.4175\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5946 - accuracy: 0.4319 - val_loss: 1.6003 - val_accuracy: 0.4315\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5556 - accuracy: 0.4452 - val_loss: 1.5332 - val_accuracy: 0.4540\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.5306 - accuracy: 0.4536 - val_loss: 1.5683 - val_accuracy: 0.4459\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.5027 - accuracy: 0.4645 - val_loss: 1.5786 - val_accuracy: 0.4397\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4880 - accuracy: 0.4673 - val_loss: 1.5148 - val_accuracy: 0.4579\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4682 - accuracy: 0.4775 - val_loss: 1.5019 - val_accuracy: 0.4629\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.4537 - accuracy: 0.4812 - val_loss: 1.5201 - val_accuracy: 0.4577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f58effb50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_momentum = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50, input_dim=32*32*3, activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dense(30, activation=keras.activations.relu),\n",
    "        keras.layers.Dense(n_classes, activation=keras.activations.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_momentum.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.5),\n",
    "    loss=keras.losses.categorical_crossentropy, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_momentum.fit(x_train_norm, one_hot_y_train, validation_data=(x_test_norm, one_hot_y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check our model's parameters count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                153650    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 155,490\n",
      "Trainable params: 155,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total parameters of $Layer_i$ is equal to $dim[Layer_{i-1}] \\times dim[Weights\\ matrix\\ layer_i] + dim[Layer_i]$.\n",
    "$$\\rightarrow Layer_1\\ params = (32\\times 32\\times 3) \\times 50 + 50 = 153650$$\n",
    "$$\\rightarrow Layer_2\\ params = 50\\times 30 + 30 = 1530$$\n",
    "$$\\rightarrow Layer_3\\ params = 30\\times 10 + 10 = 310$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 1.9302 - accuracy: 0.2855 - val_loss: 1.8363 - val_accuracy: 0.3289\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7993 - accuracy: 0.3457 - val_loss: 1.7702 - val_accuracy: 0.3469\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7593 - accuracy: 0.3613 - val_loss: 1.7474 - val_accuracy: 0.3680\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7438 - accuracy: 0.3659 - val_loss: 1.6980 - val_accuracy: 0.3873\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7265 - accuracy: 0.3727 - val_loss: 1.6805 - val_accuracy: 0.3851\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.7043 - accuracy: 0.3824 - val_loss: 1.7592 - val_accuracy: 0.3711\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6976 - accuracy: 0.3824 - val_loss: 1.6781 - val_accuracy: 0.3928\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6850 - accuracy: 0.3894 - val_loss: 1.6778 - val_accuracy: 0.3874\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6693 - accuracy: 0.3948 - val_loss: 1.6877 - val_accuracy: 0.3894\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 1.6654 - accuracy: 0.3942 - val_loss: 1.7391 - val_accuracy: 0.3650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f5c2afc40>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_momentum = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50, input_dim=32*32*3, activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dense(30, activation=keras.activations.relu),\n",
    "        keras.layers.Dense(n_classes, activation=keras.activations.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_momentum.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=keras.losses.categorical_crossentropy, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_momentum.fit(x_train_norm, one_hot_y_train, validation_data=(x_test_norm, one_hot_y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.1989 - accuracy: 0.1536 - val_loss: 2.3061 - val_accuracy: 0.1000\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3076 - accuracy: 0.0977 - val_loss: 2.3065 - val_accuracy: 0.1000\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3068 - accuracy: 0.0985 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.3060 - accuracy: 0.0996 - val_loss: 2.3056 - val_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.3059 - accuracy: 0.1010 - val_loss: 2.3057 - val_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 2.3063 - accuracy: 0.1004 - val_loss: 2.3065 - val_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 2.3056 - accuracy: 0.0989 - val_loss: 2.3048 - val_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3062 - accuracy: 0.1002 - val_loss: 2.3064 - val_accuracy: 0.1003\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3057 - accuracy: 0.0970 - val_loss: 2.3062 - val_accuracy: 0.1003\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 2.3058 - accuracy: 0.0991 - val_loss: 2.3049 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f5c52a2c0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_momentum = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50, input_dim=32*32*3, activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dense(30, activation=keras.activations.relu),\n",
    "        keras.layers.Dense(n_classes, activation=keras.activations.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_momentum.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.98),\n",
    "    loss=keras.losses.categorical_crossentropy, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_momentum.fit(x_train_norm, one_hot_y_train, validation_data=(x_test_norm, one_hot_y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the momentum term in neural network training does not always lead to better performance. A momentum value that is too high can cause the optimizer to overshoot the optimal solution and may lead to unstable or divergent behavior. Similarly, a momentum value that is too low may result in slow convergence or getting stuck in a suboptimal solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch's Effects\n",
    "In neural network training, an epoch refers to a complete iteration through the entire training dataset. During each epoch, the model's parameters are updated based on the error calculated on the training data.\n",
    "\n",
    "The number of epochs to train a neural network for can have a significant impact on the performance of the model. Training for too few epochs can result in underfitting, where the model has not had enough exposure to the training data to learn the underlying patterns. On the other hand, training for too many epochs can result in overfitting, where the model has memorized the training data and is not able to generalize well to new, unseen data.\n",
    "\n",
    "Different values of epochs can be used to adjust the trade-off between underfitting and overfitting. Some common values include:\n",
    "\n",
    "- A small number of epochs (e.g. 10-20) to quickly get a sense of whether the model is working well or not.\n",
    "- A medium number of epochs (e.g. 50-100) to get a more accurate estimate of the model's performance.\n",
    "- A large number of epochs (e.g. 200-500) to train the model for a long time and achieve the best possible performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0889 - accuracy: 0.1697 - val_loss: 0.0879 - val_accuracy: 0.1923\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0873 - accuracy: 0.2087 - val_loss: 0.0866 - val_accuracy: 0.2190\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0861 - accuracy: 0.2252 - val_loss: 0.0856 - val_accuracy: 0.2315\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0851 - accuracy: 0.2390 - val_loss: 0.0847 - val_accuracy: 0.2438\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0843 - accuracy: 0.2534 - val_loss: 0.0839 - val_accuracy: 0.2606\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0834 - accuracy: 0.2706 - val_loss: 0.0830 - val_accuracy: 0.2834\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0825 - accuracy: 0.2876 - val_loss: 0.0821 - val_accuracy: 0.2977\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0817 - accuracy: 0.3033 - val_loss: 0.0813 - val_accuracy: 0.3073\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0809 - accuracy: 0.3167 - val_loss: 0.0807 - val_accuracy: 0.3116\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0803 - accuracy: 0.3266 - val_loss: 0.0800 - val_accuracy: 0.3281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f5c42f160>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mse = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50, input_dim=32*32*3, activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dense(30, activation=keras.activations.relu),\n",
    "        keras.layers.Dense(n_classes, activation=keras.activations.softmax)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_mse.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=keras.losses.mse, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_mse.fit(x_train_norm, one_hot_y_train, validation_data=(x_test_norm, one_hot_y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE) is a commonly used loss function for regression problems, where the goal is to predict a continuous output value. However, it is not a good loss function for classification problems, where the goal is to predict a discrete class label.\n",
    "\n",
    "The main issue with using MSE for classification is that it does not take into account the fact that the output of a classification model is discrete and not continuous. MSE is sensitive to the scale of the output values, which can lead to issues when the predicted class probabilities are close to 0 or 1. MSE also does not provide a clear measure of the model's classification performance, as it does not penalize false positives and false negatives differently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Effects\n",
    "Dropout is a technique used to prevent overfitting in neural networks. The idea behind dropout is to randomly drop out, or \"turn off,\" a certain percentage of neurons in the network during training. This is done by setting the output of a randomly selected subset of neurons to zero for each training iteration. The effect of this is to force the network to learn multiple independent representations of the input data, rather than relying on a small number of neurons.\n",
    "\n",
    "Dropout has several effects on a neural network:\n",
    "\n",
    "- By randomly dropping out neurons during training, dropout introduces a form of randomness into the training process, which helps to prevent overfitting.\n",
    "- Dropout reduces the co-adaptation of neurons, meaning that during the training process, different neurons learn different features which increases the model's robustness.\n",
    "- Dropout also acts as a form of regularization, which helps to reduce the generalization error of the model.\n",
    "- It reduces the possibility of overfitting by preventing the co-adaptation of neurons in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0897 - accuracy: 0.1476 - val_loss: 0.0888 - val_accuracy: 0.1952\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0887 - accuracy: 0.1787 - val_loss: 0.0879 - val_accuracy: 0.2218\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0879 - accuracy: 0.1987 - val_loss: 0.0869 - val_accuracy: 0.2342\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0871 - accuracy: 0.2091 - val_loss: 0.0861 - val_accuracy: 0.2482\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.2252 - val_loss: 0.0852 - val_accuracy: 0.2585\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0857 - accuracy: 0.2356 - val_loss: 0.0843 - val_accuracy: 0.2717\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0851 - accuracy: 0.2445 - val_loss: 0.0837 - val_accuracy: 0.2803\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0844 - accuracy: 0.2544 - val_loss: 0.0830 - val_accuracy: 0.2930\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.0840 - accuracy: 0.2631 - val_loss: 0.0824 - val_accuracy: 0.3061\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.0835 - accuracy: 0.2701 - val_loss: 0.0819 - val_accuracy: 0.3153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f5d861c00>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            50,\n",
    "            input_dim=32*32*3,\n",
    "            activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dropout(\n",
    "            rate=0.1\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation=keras.activations.relu\n",
    "        ),\n",
    "        keras.layers.Dropout(\n",
    "            rate=0.1\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            n_classes,\n",
    "            activation=keras.activations.softmax\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss=keras.losses.mse, metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_reg.fit(x_train_norm, one_hot_y_train, validation_data=(\n",
    "    x_test_norm, one_hot_y_test), epochs=10, batch_size=32\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, dropout helps to regularize the model, reducing its capacity and forcing it to learn multiple independent representations of the input data. This can improve the model's generalization performance, which is the ability of the model to perform well on unseen data. So, dropout can make the model more robust and less overfitting by trading off a little bit of accuracy on the training set, but it can result in better performance on unseen data. This can be seen in the above results in which we have encountered a drop in accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d2e2e8a857acf4d435b79559f4d2f8a8badbfffac80b85159520f007dae8ed8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
